{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d86248e",
   "metadata": {},
   "source": [
    "# W&B Enterprise Workshop: Advanced Geological AI\n",
    "\n",
    "This hands-on workshop demonstrates how Weights & Biases acts as a system of record for a conditional diffusion workflow in subsurface modeling, using a fast, simulated setup so you can see results in ~60 minutes.\n",
    "\n",
    "- Who this is for\n",
    "  - Geoscientists, ML engineers, and platform teams experimenting with conditional diffusion on seismic-conditioned 3D volumes.\n",
    "- What you’ll accomplish in ~60 minutes\n",
    "  - Run a simulated conditional diffusion training loop with live monitoring\n",
    "  - Inspect 3D volumes (prediction, forward-modeled condition, residual) inline\n",
    "  - Log validation tables mixing metrics, images, and interactive plots\n",
    "  - Launch a short hyperparameter sweep with early termination\n",
    "  - Generate a stakeholder-ready, programmatic report\n",
    "\n",
    "What to expect\n",
    "- Runtime: end-to-end in about an hour; the model is simulated for speed.\n",
    "- Data: uses a pre-versioned dataset artifact from the W&B Registry.\n",
    "- 3D: PyVista Html renders are logged inline; ipyvolume is optional and can be disabled via config.\n",
    "- GPU: not required for this simulation.\n",
    "\n",
    "Where to look in W&B (links appear automatically after the first run)\n",
    "- Run Overview: live metrics and logs\n",
    "- System: CPU/GPU/memory correlated with your metrics\n",
    "- Artifacts: dataset lineage and model checkpoints\n",
    "- Tables: per-epoch validation table with images, Html, and metrics\n",
    "- Model Registry: tracked checkpoints with aliases (e.g., “staging”)\n",
    "- Report: auto-generated, shareable executive summary\n",
    "\n",
    "Why W&B here (neutral and value-focused)\n",
    "- Single source of truth: configs, metrics, system telemetry, artifacts, and reports in one place\n",
    "- First-class lineage: dataset → run → model graph without stitching tools\n",
    "- Rich media: images, Html 3D, and tables together for SME review\n",
    "- Governance-ready: model registry with aliases and embedded model cards\n",
    "- Programmatic reports: auto-updated, stakeholder-friendly reporting\n",
    "\n",
    "Next step: install requirements and import libraries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cef1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install minimal dependencies for the W&B workshop\n",
    "# What this does\n",
    "# - Installs W&B core (`wandb`) and Workspaces (`wandb-workspaces`) for programmatic reports\n",
    "# - Scientific stack: numpy, tqdm, scikit-image, pillow\n",
    "# - 3D backends: PyVista (default) + trame exporters; ipyvolume is optional\n",
    "# - Plotly for 2D/HTML charts; 3D volume defaults to PyVista Html renders\n",
    "#\n",
    "# 3D defaults and toggles (set in the training config)\n",
    "# - enable_3d: True/False           # disable all 3D when False\n",
    "# - enable_high_fidelity_3d: True/False  # controls PyVista renders\n",
    "# - enable_ipyvolume: True/False    # optional ipyvolume viewer\n",
    "#\n",
    "# Why W&B here\n",
    "# - Logs rich media (images, Html 3D) alongside metrics and tables for SME review without leaving the run context\n",
    "# - No GPU required for this simulation (works in local notebooks and Colab)\n",
    "\n",
    "%pip install wandb numpy tqdm wandb-workspaces plotly pillow scikit-image pyvista ipyvolume ipython-genutils trame trame-vuetify trame-vtk -q\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "import wandb_workspaces.reports.v2 as wr\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from plotly.subplots import make_subplots\n",
    "import pyvista as pv\n",
    "import ipyvolume as ipv\n",
    "from skimage.transform import resize\n",
    "from textwrap import dedent\n",
    "\n",
    "# Set PyVista to use an off-screen plotter for notebook environments\n",
    "pv.set_jupyter_backend(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417631e",
   "metadata": {},
   "source": [
    "## 1. W&B Project Configuration\n",
    "\n",
    "In this section you’ll authenticate to W&B and set `ENTITY` (team/org) and `PROJECT` (workspace for this workshop). All subsequent runs, artifacts, tables, and reports will be organized here.\n",
    "\n",
    "- What this does\n",
    "  - Initializes W&B auth for your user\n",
    "  - Defines the team `ENTITY` and `PROJECT` used by runs, artifacts, sweeps, and reports\n",
    "  - Ensures configs and system telemetry are centralized per project for easy comparison\n",
    "\n",
    "- Where to look in W&B (after the first run)\n",
    "  - Run Overview: live metrics, configs, and logs\n",
    "  - System: CPU/GPU/memory automatically captured alongside your metrics\n",
    "  - Artifacts: dataset and model lineage within this project\n",
    "  - Tables: per-epoch validation table appears under the run’s media\n",
    "\n",
    "- Authentication notes\n",
    "  - By default, runs log to `wandb.ai`. This can be changed by setting WANDB_HOST and WANDB_BASE_URL environment variables.\n",
    "  - If your API key isn’t set in the environment, the first `wandb.login()` will prompt you to paste it.\n",
    "  - You can set these environment variables to skip prompts and preselect your workspace:\n",
    "    - `WANDB_API_KEY` (find it at `https://wandb.ai/authorize`)\n",
    "    - `WANDB_ENTITY`\n",
    "    - `WANDB_PROJECT`\n",
    "\n",
    "- Why W&B here\n",
    "  - Team workspaces with RBAC keep experiments, configs, and artifacts in one place\n",
    "  - Built‑in auditability: dataset → run → model lineage without stitching tools\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Set `ENTITY` to your team and `PROJECT` to this workshop’s project name\n",
    "  - [ ] Optionally export `WANDB_API_KEY`, `WANDB_ENTITY`, `WANDB_PROJECT` as environment variables\n",
    "  - [ ] Run the auth cell; confirm you see the “View project/run” links after the first run\n",
    "  - [ ] Click through to the project page to verify organization and permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2215955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mallanstevenson\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Authentication: Entity = wandb_emea\n",
      "Project: workshop-ex123456789\n",
      "Training configuration loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ENTITY = \"wandb_emea\"  # Replace with your W&B team entity\n",
    "PROJECT = \"workshop-ex123456789\"\n",
    "\n",
    "# Ensure you have logged in and defined ENTITY and PROJECT in a previous cell\n",
    "assert \"ENTITY\" in locals(), \"Please define the ENTITY variable\"\n",
    "assert \"PROJECT\" in locals(), \"Please define the PROJECT variable\"\n",
    "\n",
    "# W&B Team Authentication\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "print(f\"W&B Authentication: Entity = {ENTITY}\")\n",
    "print(f\"Project: {PROJECT}\")\n",
    "\n",
    "# Configuration for (simulated) conditional diffusion training\n",
    "# wandb.config makes hyperparameters a first-class citizen.\n",
    "# They are saved with every run, ensuring 100% reproducibility and\n",
    "# enabling powerful, automated hyperparameter sweeps\n",
    "\n",
    "example_config = {\n",
    "    # Model Architecture\n",
    "    \"model_architecture\": \"ConditionalUNet3D\",\n",
    "    \"task\": \"geological_structure_generation\",\n",
    "    \"input_modality\": \"seismic_amplitude\",\n",
    "    \"output_modality\": \"karst_structures\",\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"epochs\": 10,\n",
    "    \"batches_per_epoch\": 20,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 4,\n",
    "    \n",
    "    # Diffusion Parameters\n",
    "    \"timesteps\": 1000,\n",
    "    \"noise_schedule\": \"cosine\",\n",
    "    \"conditioning_strength\": 0.8,\n",
    "    \n",
    "    # Geological Domain\n",
    "    \"voxel_resolution\": \"25m\",\n",
    "    \"depth_range\": \"0-800m\",\n",
    "    \"geological_context\": \"karst_detection\",\n",
    "\n",
    "    # Visualization Parameters\n",
    "    \"enable_3d\": True,\n",
    "    \"enable_high_fidelity_3d\": True,\n",
    "    \"enable_ipyvolume\": False,\n",
    "}\n",
    "\n",
    "print(\"Training configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4deb684",
   "metadata": {},
   "source": [
    "## 2. Simulation and Visualization Helpers\n",
    "\n",
    "This cell contains the helper functions for our workshop. This is not part of the core W&B integration.\n",
    "\n",
    "- What this does\n",
    "  - `simulate_conditional_diffusion_progress`: simulates learning progression for conditional diffusion (X_pred given Y)\n",
    "  - `simulate_forward_model`: approximates Y_pred = f(X_pred) to evaluate condition-consistency\n",
    "  - `plot_well_log_comparison`: interactive Plotly well-log comparison (GT vs prediction)\n",
    "  - `normalize_for_visualization`: stable normalization for images/slices\n",
    "  - Optional 3D view utilities used later in validation logging\n",
    "\n",
    "- Where to look in W&B (after first validation epoch)\n",
    "  - Media: `Viz/diagnostics/central_slice_grid` (2D grid of Y, X, X_pred, Residual)\n",
    "  - Media: `Viz3D/PyVista_Renders/*` (inline Html 3D renders for prediction and residual)\n",
    "  - Tables: `val_table/validation_table` (per-epoch rows with images, Html, metrics, and well-log plot)\n",
    "\n",
    "- 3D backends (defaults and options)\n",
    "  - Default: PyVista Html renders for a responsive, stable inline 3D experience\n",
    "  - Optional: ipyvolume can be enabled via config; Plotly 3D (Tier 1/2) is optional and disabled by default for speed\n",
    "  - You can control 3D via config toggles: `enable_3d`, `enable_high_fidelity_3d`, `enable_ipyvolume`\n",
    "\n",
    "- Why W&B here\n",
    "  - Rich media (Html 3D + images) is logged alongside metrics and tables, enabling SME review directly in the run context\n",
    "  - Results are comparable across runs without managing files or screenshots\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Set `enable_3d=False` in config to see a lightweight, metrics-only run\n",
    "  - [ ] Re-enable `enable_high_fidelity_3d=True` to inspect PyVista Html renders\n",
    "  - [ ] Toggle `enable_ipyvolume=True` to compare 3D backends\n",
    "  - [ ] Inspect `val_table/validation_table` and expand a row to view all media for a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d86083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By returning a wandb.Html object, we can log custom, interactive visualizations\n",
    "# like this Plotly chart directly into the W&B dashboard. This allows domain experts\n",
    "# to analyze results without switching contexts or downloading files.\n",
    "def plot_well_log_comparison(gt_log: np.ndarray, pred_log: np.ndarray, depth: np.ndarray) -> wandb.Html:\n",
    "    \"\"\"Creates an interactive Plotly chart comparing ground truth and predicted well logs.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=gt_log, y=depth, mode='lines', name='Ground Truth Log', line=dict(color='black')))\n",
    "    fig.add_trace(go.Scatter(x=pred_log, y=depth, mode='lines', name='Predicted Log', line=dict(color='crimson', dash='dash')))\n",
    "    fig.update_layout(\n",
    "        title=\"Well Log Comparison\",\n",
    "        xaxis_title=\"Signal Amplitude\",\n",
    "        yaxis_title=\"Depth (m)\",\n",
    "        yaxis_autorange='reversed' # Depth increases downwards\n",
    "    )\n",
    "    html = pio.to_html(fig)\n",
    "    return wandb.Html(html)\n",
    "\n",
    "def generate_synthetic_loss(\n",
    "    step: int,\n",
    "    schedule: str = \"cosine\",\n",
    "    conditioning_strength: float = 0.8,\n",
    "    learning_rate: float = 1e-3,\n",
    "    batch_size: int = 4,\n",
    "    base_seed: int = 42,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Parameterized synthetic loss that responds to sweep knobs.\n",
    "    - schedule: shapes the decay (cosine|linear|sigmoid)\n",
    "    - conditioning_strength: higher => faster improvement\n",
    "    - learning_rate: modestly speeds decay\n",
    "    - batch_size: larger => lower noise\n",
    "    Deterministic per step via base_seed + step.\n",
    "    \"\"\"\n",
    "    # Progress in [0, 1]\n",
    "    progress = np.clip(step / 600.0, 0.0, 1.0)\n",
    "\n",
    "    if schedule == \"linear\":\n",
    "        sched = progress\n",
    "    elif schedule == \"sigmoid\":\n",
    "        sched = 1.0 / (1.0 + np.exp(-10.0 * (progress - 0.5)))\n",
    "    else:  # cosine\n",
    "        sched = 0.5 - 0.5 * np.cos(np.pi * progress)\n",
    "\n",
    "    # Faster decay with stronger conditioning and slightly higher LR\n",
    "    decay_speed = 1.0 + 0.8 * conditioning_strength + 0.3 * np.log10(max(learning_rate, 1e-6) / 1e-3 + 1.0)\n",
    "    base_curve = 1.5 * np.exp(-3.0 * sched * decay_speed) + 0.05\n",
    "\n",
    "    # Noise shrinks with batch size\n",
    "    rng = np.random.RandomState(int(base_seed) + int(step))\n",
    "    noise = rng.normal(0.0, 0.05 / max(batch_size, 1))\n",
    "\n",
    "    return float(max(0.005, base_curve + noise))\n",
    "\n",
    "# Simulation controls: \n",
    "# conditioning_strength controls structure emergence\n",
    "# noise_schedule (‘cosine’, ‘linear’, ‘sigmoid’) controls noise decay shape\n",
    "# Runs are deterministic per epoch via base_seed\n",
    "def simulate_conditional_diffusion_progress(\n",
    "    seismic_condition: np.ndarray,\n",
    "    karst_target: np.ndarray,\n",
    "    epoch: int,\n",
    "    total_epochs: int = 10,\n",
    "    conditioning_strength: float = 0.8,\n",
    "    noise_schedule: str = \"cosine\",\n",
    "    base_seed: int = 42,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate conditional diffusion learning progression (single-channel).\n",
    "    - conditioning_strength: scales structure emergence (higher = stronger alignment to karst_target)\n",
    "    - noise_schedule: 'cosine' | 'linear' | 'sigmoid' controls noise decay shape over epochs\n",
    "    - Deterministic per epoch via base_seed + epoch\n",
    "    \"\"\"\n",
    "    # Training progress (0.0 at start, 1.0 at end) → used to shape schedule\n",
    "    progress = epoch / float(max(1, total_epochs - 1))\n",
    "\n",
    "    # Deterministic seed derived from base_seed and epoch\n",
    "    np.random.seed(int(base_seed) + int(epoch) * 1000)\n",
    "\n",
    "    # Schedule shaping (affects how fast noise decreases / structure increases)\n",
    "    if noise_schedule == \"linear\":\n",
    "        schedule_factor = progress\n",
    "    elif noise_schedule == \"sigmoid\":\n",
    "        schedule_factor = 1.0 / (1.0 + np.exp(-12.0 * (progress - 0.5)))\n",
    "    else:  # \"cosine\" default\n",
    "        schedule_factor = 0.5 - 0.5 * np.cos(np.pi * progress)\n",
    "\n",
    "    # Stage 1 (epochs 0–3): learn basic correlations; high noise\n",
    "    if epoch <= 3:\n",
    "        noise_level = 0.8 - (epoch / 3.0) * 0.4          # 0.8 → 0.4\n",
    "        noise_level *= (1.0 - 0.25 * schedule_factor)    # slightly faster decay with schedule\n",
    "        structural_learning = (epoch / 3.0) * 0.3        # 0.0 → 0.3\n",
    "        structural_learning *= conditioning_strength\n",
    "\n",
    "        structure_mask = (seismic_condition > np.percentile(seismic_condition, 60)).astype(float)\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        prediction = (\n",
    "            noise * 0.7 +\n",
    "            seismic_condition * structural_learning +\n",
    "            karst_target * structure_mask * 0.1\n",
    "        )\n",
    "\n",
    "    # Stage 2 (epochs 4–6): refine geological structures; reduce noise\n",
    "    elif epoch <= 6:\n",
    "        stage_progress = (epoch - 4.0) / 2.0             # 0.0 → 1.0\n",
    "        karst_regions = (\n",
    "            (seismic_condition > np.percentile(seismic_condition, 40)) &\n",
    "            (seismic_condition < np.percentile(seismic_condition, 85))\n",
    "        )\n",
    "\n",
    "        noise_level = 0.4 - stage_progress * 0.25        # 0.4 → 0.15\n",
    "        noise_level *= (1.0 - 0.25 * schedule_factor)\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        geological_understanding = 0.3 + stage_progress * 0.4   # 0.3 → 0.7\n",
    "        geological_understanding *= conditioning_strength\n",
    "\n",
    "        prediction = (\n",
    "            noise * 0.3 +\n",
    "            karst_target * karst_regions * geological_understanding +\n",
    "            seismic_condition * 0.2 * (1 - karst_regions)\n",
    "        )\n",
    "\n",
    "    # Stage 3 (epochs 7–9): fine-tuning; high accuracy, low noise\n",
    "    else:\n",
    "        stage_progress = (epoch - 7.0) / 2.0             # 0.0 → 1.0\n",
    "        noise_level = 0.15 - stage_progress * 0.10       # 0.15 → 0.05\n",
    "        noise_level *= (1.0 - 0.25 * schedule_factor)\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        accuracy = 0.7 + stage_progress * 0.25           # 0.7 → 0.95\n",
    "        accuracy *= (0.85 + 0.3 * conditioning_strength)\n",
    "        accuracy = np.clip(accuracy, 0.0, 1.0)\n",
    "\n",
    "        uncertainty_mask = np.random.random(seismic_condition.shape) < 0.1\n",
    "\n",
    "        prediction = (\n",
    "            karst_target * accuracy +\n",
    "            noise * 0.1 +\n",
    "            seismic_condition * uncertainty_mask * 0.05\n",
    "        )\n",
    "\n",
    "    # Keep realistic value ranges and avoid exact zeros in residuals\n",
    "    prediction = np.clip(prediction, 0, 1)\n",
    "    prediction += np.random.uniform(-1e-9, 1e-9, prediction.shape)\n",
    "    return prediction\n",
    "\n",
    "def normalize_for_visualization(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize geological data for W&B visualization with proper contrast.\"\"\"\n",
    "    data_min, data_max = np.min(data), np.max(data)\n",
    "    if data_max == data_min:\n",
    "        return np.full_like(data, 0.5)\n",
    "    normalized = (data - data_min) / (data_max - data_min)\n",
    "    # Apply gamma correction for better geological feature visibility\n",
    "    return np.power(normalized, 0.7)\n",
    "\n",
    "def simulate_forward_model(x_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulates a forward model y=f(x) to generate a predicted condition y_pred.\n",
    "    This step is crucial for evaluating the \"cycle consistency\" of our generator;\n",
    "    we check if the forward model of our prediction (y_pred) matches the original input condition (y).\n",
    "    In a real scenario, this would be a physics-based or learned model.\n",
    "    Here, we simulate it by applying a slight blur and adding minor noise.\n",
    "    \"\"\"\n",
    "    # Apply a simple blurring effect (convolution with a small kernel)\n",
    "    kernel = np.ones((3, 3, 3)) / 27.0\n",
    "    # Use scipy for convolution if available, otherwise a simpler method\n",
    "    try:\n",
    "        from scipy.ndimage import convolve\n",
    "        blurred = convolve(x_pred, kernel, mode='reflect')\n",
    "    except ImportError:\n",
    "        # Fallback if scipy is not installed\n",
    "        blurred = x_pred\n",
    "        \n",
    "    # Add a small amount of random noise\n",
    "    noise = np.random.normal(0, 0.02, x_pred.shape)\n",
    "    y_pred = blurred + noise\n",
    "    \n",
    "    return np.clip(y_pred, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077d07b",
   "metadata": {},
   "source": [
    "### Tier 1 Analysis: Global Sanity Check (Downsampled View)\n",
    "\n",
    "**The Question:** \"Is the model globally stable?\" Before diving into details, we need a quick, high-level check of the entire volume.\n",
    "\n",
    "**The Technique:** A downsampled 3D comparison (e.g., 128³ → 64³) is ideal for fast, low-latency inspection.\n",
    "\n",
    "Current implementation status\n",
    "- The Plotly-based downsampled 3D comparison (`create_downsampled_comparison`) is defined but not currently logged due to stability/performance trade-offs in notebook environments. The logging lines are commented out.\n",
    "- You can still assess global stability using the per-epoch 2D central-slice grid and (if enabled) PyVista Html renders.\n",
    "\n",
    "Where to look in W&B\n",
    "- Tables: `val_table/validation_table` (per-epoch rows with images and the well-log Plotly Html)\n",
    "- Media: if enabled, 3D Html appears under `Viz3D/PyVista_Renders/*` (prediction, residual)\n",
    "\n",
    "Why W&B here\n",
    "- Downsampled overviews and detailed media are tracked in the same run context, so reviewers don’t switch tools\n",
    "- Results remain versioned and comparable across runs and sweeps\n",
    "\n",
    "Try it yourself\n",
    "- [ ] Run a short training; open the run and expand a row in `val_table/validation_table`\n",
    "- [ ] Compare early vs late epochs to see stability changes in the 2D grid (`Viz/diagnostics/central_slice_grid`)\n",
    "- [ ] Optional: enable 3D (PyVista) via config toggles (`enable_3d=True`, `enable_high_fidelity_3d=True`)\n",
    "- [ ] Future improvement: re-enable the Plotly 3D logging lines in the validation loop once environment constraints allow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b0aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_downsampled_comparison(volumes: Dict[str, np.ndarray]) -> go.Figure:\n",
    "    \"\"\"Downsamples volumes and returns a side-by-side Plotly figure.\"\"\"\n",
    "    target_shape = (64, 64, 64)\n",
    "    subplot_titles = [name.replace(\"_\", \" \") for name in volumes.keys()]\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=len(volumes),\n",
    "        specs=[[{'type': 'volume'}] * len(volumes)],\n",
    "        subplot_titles=subplot_titles\n",
    "    )\n",
    "    for i, (name, data) in enumerate(volumes.items()):\n",
    "        resized_data = resize(data, target_shape, anti_aliasing=True)\n",
    "        vmin, vmax = float(np.min(resized_data)), float(np.max(resized_data))\n",
    "        if vmax == vmin: vmax = vmin + 1.0\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                value=resized_data,                 # pass 3D array directly\n",
    "                cmin=vmin, cmax=vmax,\n",
    "                isomin=vmin + (vmax - vmin) * 0.02,\n",
    "                isomax=vmax - (vmax - vmin) * 0.02,\n",
    "                opacity=0.15, opacityscale=\"uniform\",\n",
    "                surface_count=12,\n",
    "                colorscale='RdBu' if ('Residual' in name or 'Error' in name) else 'viridis',\n",
    "            ),\n",
    "            row=1, col=i + 1\n",
    "        )\n",
    "    fig.update_layout(title_text=\"Downsampled 3D Comparison\", height=420, margin=dict(t=50, b=10, l=10, r=10))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77f75e",
   "metadata": {},
   "source": [
    "### Tier 2 Analysis: Fine-Detail Inspection (Cropped View)\n",
    "\n",
    "**The Question:** \"Now that the global structure looks right, is the model accurately preserving fine details?\"\n",
    "\n",
    "**The Technique:** We extract a smaller cube (e.g., 64³) from the center of the original, full‑resolution volumes. This allows inspection of a specific region without downsampling.\n",
    "\n",
    "Current implementation status\n",
    "- The Plotly-based cropped 3D comparison (`create_cropped_comparison`) is defined but its logging is currently commented out due to notebook environment stability/performance constraints.\n",
    "- This function is not connected to the validation table. The table currently logs 2D slices and a well‑log Plotly Html produced elsewhere.\n",
    "\n",
    "Where to look in W&B (available today)\n",
    "- Media: `Viz/diagnostics/central_slice_grid` for 2D central‑slice grids (Y, X, X_pred, Residual)\n",
    "- Media: `Viz3D/PyVista_Renders/*` for inline Html 3D renders (prediction, residual) if 3D is enabled\n",
    "\n",
    "Why W&B here\n",
    "- Detailed media and metrics live in the same run context, enabling SME review without switching tools\n",
    "- Results remain versioned and comparable across runs and sweeps\n",
    "\n",
    "Try it yourself\n",
    "- [ ] Enable PyVista 3D via config (`enable_3d=True`, `enable_high_fidelity_3d=True`) and compare epochs 0 / mid / last\n",
    "- [ ] Inspect `Viz/diagnostics/central_slice_grid` in the Media panel for texture/sharpness\n",
    "- [ ] Future improvement: re‑enable the Plotly cropped 3D logging lines when environment constraints allow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cropped_comparison(volumes: Dict[str, np.ndarray]) -> go.Figure:\n",
    "    \"\"\"Crops the center of volumes and returns a side-by-side Plotly figure.\"\"\"\n",
    "    crop_size = 64\n",
    "    subplot_titles = [name.replace(\"_\", \" \") for name in volumes.keys()]\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=len(volumes),\n",
    "        specs=[[{'type': 'volume'}] * len(volumes)],\n",
    "        subplot_titles=subplot_titles\n",
    "    )\n",
    "    for i, (name, data) in enumerate(volumes.items()):\n",
    "        if all(dim >= crop_size for dim in data.shape):\n",
    "            center = [dim // 2 for dim in data.shape]\n",
    "            start = [c - crop_size // 2 for c in center]\n",
    "            cropped_data = data[\n",
    "                start[0]:start[0]+crop_size,\n",
    "                start[1]:start[1]+crop_size,\n",
    "                start[2]:start[2]+crop_size\n",
    "            ]\n",
    "        else:\n",
    "            cropped_data = data\n",
    "        vmin, vmax = float(np.min(cropped_data)), float(np.max(cropped_data))\n",
    "        if vmax == vmin: vmax = vmin + 1.0\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                value=cropped_data,                # pass 3D array directly\n",
    "                cmin=vmin, cmax=vmax,\n",
    "                isomin=vmin + (vmax - vmin) * 0.02,\n",
    "                isomax=vmax - (vmax - vmin) * 0.02,\n",
    "                opacity=0.15, opacityscale=\"uniform\",\n",
    "                surface_count=12,\n",
    "                colorscale='RdBu' if ('Residual' in name or 'Error' in name) else 'viridis',\n",
    "            ),\n",
    "            row=1, col=i + 1\n",
    "        )\n",
    "    fig.update_layout(title_text=\"Cropped (Full-Res) 3D Comparison\", height=420, margin=dict(t=50, b=10, l=10, r=10))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06aea2",
   "metadata": {},
   "source": [
    "### Tier 3 Analysis: Debugging with the Residual (High-Fidelity Render)\n",
    "\n",
    "**The Question:** \"Where, specifically, is my model failing?\" To improve the model, we must understand the nature and location of its errors.\n",
    "\n",
    "**The Technique:** We use a high-performance library like PyVista (default) or ipyvolume (optional) to create the best possible render of the most critical volume: the **residual** (`AI_Condition_Y_pred - Input_Condition_Y`). This visualizes error structure in 3D.\n",
    "\n",
    "**What We Look For:**\n",
    "- **Systematic Errors:** Are large errors concentrated in a specific geological layer or region?\n",
    "- **Error Polarity:** Over‑prediction (positive residual) vs under‑prediction (negative residual).\n",
    "- **Interactivity:** Peel back layers via opacity to locate problematic horizons.\n",
    "\n",
    "Current implementation status\n",
    "- PyVista Html renders are generated (0 / mid / last epoch) when `enable_3d=True` and `enable_high_fidelity_3d=True`.\n",
    "- ipyvolume can be enabled via `enable_ipyvolume=True` (optional).\n",
    "- Plotly 3D volume logging is intentionally disabled in this workshop for stability/performance in notebooks.\n",
    "\n",
    "Where to look in W&B\n",
    "- Media: `Viz3D/PyVista_Renders/*` (AI prediction and residual 3D Html)\n",
    "- Media: `Viz/diagnostics/central_slice_grid` (compact 2D context per epoch)\n",
    "\n",
    "Why W&B here\n",
    "- Inline 3D Html is logged alongside metrics/tables, enabling SME review in the run context\n",
    "- Results are versioned, comparable across runs/sweeps, and traceable via lineage\n",
    "\n",
    "Try it yourself\n",
    "- [ ] Ensure `enable_3d=True` and `enable_high_fidelity_3d=True`; compare epochs 0 / mid / last\n",
    "- [ ] Toggle `enable_ipyvolume=True` to compare backends\n",
    "- [ ] Use the residual render to target misfit regions for data curation or hyperparameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7868f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyvista_render(volume: np.ndarray, title: str) -> str:\n",
    "    \"\"\"\n",
    "    Render a single volume with PyVista and return HTML.\n",
    "    - Downsamples large volumes to speed export\n",
    "    - Uses ImageData; compatible with older PyVista versions\n",
    "    \"\"\"\n",
    "    html_filename = f\"{title.replace(' ', '_').replace('(', '').replace(')', '')}_temp.html\"\n",
    "    try:\n",
    "        # Downsample aggressively if needed (keep <= 96^3)\n",
    "        max_dim = 96\n",
    "        dz, dy, dx = map(int, volume.shape)\n",
    "        scale = max(1, max(dz, dy, dx) // max_dim)\n",
    "        target = (max(1, dz // scale), max(1, dy // scale), max(1, dx // scale))\n",
    "        vol_ds = volume if (dz, dy, dx) == target else resize(volume, target, anti_aliasing=True)\n",
    "        vol_ds = np.asarray(vol_ds, dtype=np.float32, order=\"F\")\n",
    "\n",
    "        # Build an ImageData grid (works across PyVista versions)\n",
    "        nz, ny, nx = vol_ds.shape  # z, y, x\n",
    "        grid = pv.ImageData(dimensions=(nx, ny, nz))  # note order: x, y, z\n",
    "        grid.spacing = (1.0, 1.0, 1.0)\n",
    "        grid.origin = (0.0, 0.0, 0.0)\n",
    "        grid.point_data[\"values\"] = vol_ds.flatten(order=\"F\")\n",
    "\n",
    "        plotter = pv.Plotter(off_screen=True, notebook=True, window_size=(800, 600))\n",
    "        plotter.add_volume(\n",
    "            grid,\n",
    "            scalars=\"values\",\n",
    "            cmap=\"RdBu\" if (\"Residual\" in title or \"Error\" in title) else \"viridis\",\n",
    "            opacity=\"sigmoid\",\n",
    "            shade=True,\n",
    "        )\n",
    "        plotter.add_axes()\n",
    "        plotter.export_html(html_filename)\n",
    "        html = Path(html_filename).read_text()\n",
    "        plotter.close()\n",
    "        return html\n",
    "    except Exception as e:\n",
    "        return f\"<p>PyVista rendering failed: {e}</p>\"\n",
    "    finally:\n",
    "        try:\n",
    "            if os.path.exists(html_filename):\n",
    "                os.remove(html_filename)\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2ba0e",
   "metadata": {},
   "source": [
    "## 3. The Core Training Function with W&B Integration\n",
    "\n",
    "This function encapsulates the entire training and evaluation workflow. It serves as a blueprint for a reproducible, auditable, and transparent ML lifecycle. Each section is clearly marked to show how a specific W&B feature is used to track, version, and evaluate the model, turning a standard training script into an enterprise-ready system of record.\n",
    "\n",
    "Notation and channel scope  \n",
    "X: ground-truth geology (karst), X_pred: generated prediction  \n",
    "Y: input seismic condition, Y_pred = f(X_pred)  \n",
    "Residual = Y_pred − Y  \n",
    "\n",
    "Single-channel visuals: This demo renders a single channel for stability and speed. Multi-channel rendering/metrics are feasible (loop over channels and log per-channel), but intentionally out of scope here.\n",
    "\n",
    "- What this does\n",
    "  - Initializes a W&B run with `ENTITY`/`PROJECT`, config, tags\n",
    "  - Declares and downloads a versioned dataset artifact (lineage: dataset → run)\n",
    "  - Simulates training and logs live metrics; correlates with system telemetry\n",
    "  - Per-epoch validation: logs a rich `val_table/validation_table` (images + well‑log Html) and, if enabled, 3D Html renders (0/mid/last)\n",
    "  - Tracks best validation loss and versions a model checkpoint as an artifact; links it in the Model Registry with alias (e.g., `staging`)\n",
    "  - Finishes the run cleanly\n",
    "\n",
    "- Where to look in W&B\n",
    "  - Run Overview: live metrics and config\n",
    "  - System: CPU/GPU/memory correlated with training metrics\n",
    "  - Artifacts: dataset (`CigKarst:v0`) and model checkpoint (`conditional-diffusion-checkpoint`)\n",
    "  - Media: `Viz/diagnostics/central_slice_grid`, `Viz3D/PyVista_Renders/*` (if 3D enabled)\n",
    "  - Tables: `val_table/validation_table` (per-epoch rows with images + well‑log Plotly Html)\n",
    "  - Model Registry: model registered with an alias (e.g., `staging`) for retrieval/CI\n",
    "\n",
    "- Why W&B here\n",
    "  - End-to-end lineage and governance: dataset → runs → models, without stitching tools\n",
    "  - Rich media (images + Html 3D) and tables live in the same run context for SME review\n",
    "  - Model Registry aliases provide stable pointers for promotion and CI/CD workflows\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Confirm `ENTITY`/`PROJECT` are set; run the cell\n",
    "  - [ ] Open the run link; monitor live metrics and the System tab\n",
    "  - [ ] Expand a row in `val_table/validation_table` to inspect images and well‑log Html\n",
    "  - [ ] If 3D is enabled, open `Viz3D/PyVista_Renders/*` (0/mid/last)\n",
    "  - [ ] Find the model artifact and verify the registry alias (e.g., `staging`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f1b66",
   "metadata": {},
   "source": [
    "### About the central slice grid (per‑epoch 2D diagnostic)\n",
    "\n",
    "- What it is\n",
    "  - A compact 2×2 view from the central slice of each 3D volume:\n",
    "    - Top: Y (seismic input), X (ground‑truth geology)\n",
    "    - Bottom: X_pred (prediction), Residual (X_pred − X) normalized around 0\n",
    "- Why it matters\n",
    "  - Fast, per‑epoch qualitative check of conditioning consistency and structural fidelity without rendering full 3D.\n",
    "  - Lets SMEs see whether structure emerges and residuals shrink/localize as training progresses.\n",
    "- How to read it\n",
    "  - Compare X vs X_pred for texture and boundaries; the residual should decrease and concentrate around true misfit regions.\n",
    "  - Large, structured residuals suggest systematic errors (bias, misalignment, or forward‑model mismatch).\n",
    "- Tips\n",
    "  - If residuals are uniformly high: revisit conditioning strength or forward‑model assumptions.\n",
    "  - If checkerboard artifacts appear: check upsampling/architecture or normalization.\n",
    "  - For localized issues, open the corresponding PyVista Html render under `Viz3D/PyVista_Renders/*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40728477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conditional_diffusion(config=None):\n",
    "    \"\"\"\n",
    "    Train a conditional diffusion model for geological structure generation.\n",
    "    This function is instrumented with W&B to track the entire lifecycle.\n",
    "    \"\"\"\n",
    "    # ===================================================================\n",
    "    # 1. W&B SETUP: Initialize Run and Centralize Configuration\n",
    "    #    - wandb.init() starts a new run to track this experiment.\n",
    "    #    - wandb.config pulls hyperparameter settings, making them available to sweeps.\n",
    "    # ===================================================================\n",
    " \n",
    "\n",
    "    # Initialize a new W&B run\n",
    "    run = wandb.init(\n",
    "        entity=ENTITY,\n",
    "        project=PROJECT,\n",
    "        config=(config or example_config), # use config if it exists, otherwise use example_config (useful for sweeps)\n",
    "        # job_type and tags are powerful organizational tools that make it easy\n",
    "        # to filter, group, and compare runs across a large project in the W&B UI\n",
    "        job_type=\"training\",\n",
    "        tags=[\"conditional-diffusion\"]\n",
    "    )\n",
    "\n",
    "    # Use the config from W&B (this allows sweeps to override values)\n",
    "    config = wandb.config # this is a dictionary of the hyperparameters\n",
    "    np.random.seed(config.get(\"seed\", 42))  # set global seed once\n",
    "\n",
    "    # ===================================================================\n",
    "    # 2. W&B ARTIFACTS: Versioning and Loading the Dataset\n",
    "    #    - run.use_artifact() declares a dependency on a specific dataset version.\n",
    "    #    - This creates a lineage graph, giving us a full audit trail.\n",
    "    # ===================================================================\n",
    "    # Load CigKarst dataset from W&B Registry\n",
    "    \n",
    "    \n",
    "    # run.use_artifact() creates a direct link to the dataset version used for this run.\n",
    "    # This automatically generates a complete, visual data-to-model lineage graph,\n",
    "    # which is essential for auditability and debugging.\n",
    "    artifact = run.use_artifact('wandb-registry-dataset/CigKarst:latest', type='dataset')\n",
    "    artifact_dir = artifact.download()\n",
    "\n",
    "    # Load geological samples from the dataset\n",
    "    geological_samples = []\n",
    "\n",
    "    metadata_path = Path(artifact_dir) / \"dataset_metadata.json\"\n",
    "\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            meta = json.load(f)\n",
    "        samples = meta.get(\"samples\", [])\n",
    "        total_samples = int(meta.get(\"total_samples\", 0))\n",
    "        for sample_info in samples:\n",
    "            seismic_file = Path(artifact_dir) / sample_info[\"seismic_file\"]\n",
    "            karst_file = Path(artifact_dir) / sample_info[\"karst_file\"]\n",
    "            if seismic_file.exists() and karst_file.exists():\n",
    "                seismic_data = np.load(seismic_file)\n",
    "                karst_data = np.load(karst_file)\n",
    "                # Sanity checks for determinism and structure\n",
    "                assert seismic_data.dtype == np.float32 and karst_data.dtype == np.float32, (seismic_data.dtype, karst_data.dtype)\n",
    "                assert seismic_data.shape == (64, 64, 64) and karst_data.shape == (64, 64, 64), (seismic_data.shape, karst_data.shape)\n",
    "                sample = {\n",
    "                    \"seismic\": seismic_data,\n",
    "                    \"karst\": karst_data,\n",
    "                    \"sample_id\": sample_info[\"sample_id\"],\n",
    "                    \"coordinates\": sample_info[\"coordinates\"],\n",
    "                    \"source\": sample_info[\"source_volume\"],\n",
    "                }\n",
    "                geological_samples.append(sample)\n",
    "        assert len(geological_samples) == total_samples, (len(geological_samples), total_samples)\n",
    "        print(f\"Loaded {len(geological_samples)} real geological samples from CigKarst\")\n",
    "    else:\n",
    "        print(\"Metadata file not found in artifact\")\n",
    "        run.finish()\n",
    "        return None\n",
    "\n",
    "    # Select a fixed set of samples for consistent validation across runs\n",
    "    good_sample_ids = [\"volume_0_patch_1\", \"volume_0_patch_3\", \"volume_1_patch_0\"]\n",
    "    fixed_samples = [s for s in geological_samples if s['sample_id'] in good_sample_ids]\n",
    "    if len(fixed_samples) != len(good_sample_ids):\n",
    "        raise ValueError(f\"Error: Could not find all specified good samples.\")\n",
    "    print(f\"Selected {len(fixed_samples)} pre-validated samples for tracking.\")\n",
    "\n",
    "    # Track best model\n",
    "    best_validation_loss = float('inf')\n",
    "\n",
    "    # ===================================================================\n",
    "    # 3. W&B TRAINING LOOP: Logging Live Metrics\n",
    "    #    - run.log() is called inside the loop to stream metrics in real-time.\n",
    "    #    - This allows us to monitor model performance and system utilization live from the dashboard.\n",
    "    # ===================================================================\n",
    "    for epoch in range(config.get(\"epochs\", 10)):\n",
    "        print(f\"Epoch {epoch}: Simulating conditional diffusion training...\")\n",
    "        batches_per_epoch = config.get(\"batches_per_epoch\", 20)\n",
    "        \n",
    "        for batch in range(batches_per_epoch):\n",
    "            step = epoch * batches_per_epoch + batch\n",
    "            # Simulate training progress and calculate synthetic losses\n",
    "            noise_pred_loss = generate_synthetic_loss(\n",
    "            step,\n",
    "            schedule=str(config.get(\"noise_schedule\", \"cosine\")),\n",
    "            conditioning_strength=float(config.get(\"conditioning_strength\", 0.8)),\n",
    "            learning_rate=float(config.get(\"learning_rate\", 1e-3)),\n",
    "            batch_size=int(config.get(\"batch_size\", 4)),\n",
    "            base_seed=int(config.get(\"seed\", 42)),\n",
    "            )\n",
    "            reconstruction_proxy = generate_synthetic_loss(\n",
    "            int(step * 1.5),\n",
    "            schedule=str(config.get(\"noise_schedule\", \"cosine\")),\n",
    "            conditioning_strength=float(config.get(\"conditioning_strength\", 0.8)),\n",
    "            learning_rate=float(config.get(\"learning_rate\", 1e-3)),\n",
    "            batch_size=int(config.get(\"batch_size\", 4)),\n",
    "            base_seed=int(config.get(\"seed\", 42)),\n",
    "             )\n",
    "            total_loss = 0.6 * noise_pred_loss + 0.4 * reconstruction_proxy\n",
    "\n",
    "            # Prepare log dictionary for training metrics\n",
    "            # Training-time proxy metrics (synthetic): reconstruction_mse approximates X_pred vs X; true condition-consistency is computed at validation.\n",
    "            log_dict = {\n",
    "            \"train/noise_prediction_loss\": noise_pred_loss,\n",
    "            \"train/reconstruction_mse\": reconstruction_proxy,  # X_pred vs X (synthetic proxy during training)\n",
    "            \"train/total_loss\": total_loss,\n",
    "            \"train/learning_rate\": config.get(\"learning_rate\", 1e-3) * (0.95 ** (epoch // 3))\n",
    "            }\n",
    "            \n",
    "            # SINGLE wandb.log call per training step. W&B automatically captures system\n",
    "            # metrics (CPU/GPU utilization, memory) alongside your custom metrics, providing\n",
    "            # a holistic view to diagnose performance bottlenecks in real-time.\n",
    "            run.log(log_dict)\n",
    "\n",
    "        # ===================================================================\n",
    "        # 4. W&B VALIDATION: Logging Rich Media and Tables\n",
    "        #    - At the end of each epoch, we log qualitative results.\n",
    "        #    - wandb.Image() for visual comparison.\n",
    "        #    - wandb.Html() for custom, interactive Plotly charts.\n",
    "        #    - wandb.Table() to create structured, sortable tables of predictions.\n",
    "        # ===================================================================\n",
    "        \n",
    "        \n",
    "        # wandb.Table creates a rich, interactive table in the UI. This allows for\n",
    "        # sorting and filtering results, and comparing images, plots, and metrics\n",
    "        # side-by-side across different runs—all within a single view.\n",
    "        validation_table = wandb.Table(columns=[\n",
    "        \"epoch\", \"sample_id\", \"seismic_input\", \"ground_truth\",\n",
    "        \"prediction\", \"residual_map\", \"well_log_comparison\",\n",
    "        \"reconstruction_mse\", \"condition_consistency_mse\", \"ssim_score\", \"log_correlation\"\n",
    "        ])\n",
    "            \n",
    "        total_reconstruction_mse = 0.0\n",
    "        total_condition_consistency_mse = 0.0\n",
    "\n",
    "        # --- NEW: Create visualizations for a small BATCH of validation samples ---\n",
    "        # We will create a unique key for each visualization in the log dictionary.\n",
    "        visualizations_log = {}\n",
    "        \n",
    "        for sample in fixed_samples:\n",
    "            \n",
    "            # Generate the necessary volumes for this specific sample\n",
    "            prediction_3d = simulate_conditional_diffusion_progress(\n",
    "            sample['seismic'],\n",
    "            sample['karst'],\n",
    "            epoch,\n",
    "            total_epochs=int(config.get(\"epochs\", 10)),\n",
    "            conditioning_strength=float(config.get(\"conditioning_strength\", 0.8)),\n",
    "            noise_schedule=str(config.get(\"noise_schedule\", \"cosine\")),\n",
    "            base_seed=int(config.get(\"seed\", 42)),\n",
    "            )\n",
    "\n",
    "            y_pred_3d = simulate_forward_model(prediction_3d)\n",
    "            volumes_for_viz = {\n",
    "                \"Input_Seismic_(Y)\": sample['seismic'],\n",
    "                \"Ground_Truth_Karst_(X)\": sample['karst'],\n",
    "                \"Predicted_Karst_(X_pred)\": prediction_3d,\n",
    "                \"Forward_Model_Seismic_(Y_pred)\": y_pred_3d,\n",
    "                \"Model_Error_(Residual)\": y_pred_3d - sample['seismic']\n",
    "            }\n",
    "            \n",
    "            #start\n",
    "            # 3D: zero/mid/last only; single-channel; PyVista default; ipyvolume off by default.\n",
    "            epochs_total = int(config.get(\"epochs\", 10))\n",
    "            mid_epoch = (epochs_total - 1) // 2\n",
    "            should_log_3d = bool(config.get(\"enable_3d\", True)) and (epoch in [0, mid_epoch, epochs_total - 1])\n",
    "\n",
    "            if should_log_3d and sample['sample_id'] == fixed_samples[0]['sample_id']:\n",
    "                volumes_for_viz = {\n",
    "                    \"Predicted_Karst_(X_pred)\": prediction_3d,\n",
    "                    \"Forward_Model_Seismic_(Y_pred)\": y_pred_3d,\n",
    "                    \"Model_Error_(Residual)\": y_pred_3d - sample['seismic'],\n",
    "                }\n",
    "                ''' Removing the plotly figures for now\n",
    "                ds_fig = create_downsampled_comparison({\n",
    "                    \"Predicted_Karst_(X_pred)\": volumes_for_viz[\"Predicted_Karst_(X_pred)\"],\n",
    "                    \"Forward_Model_Seismic_(Y_pred)\": volumes_for_viz[\"Forward_Model_Seismic_(Y_pred)\"],\n",
    "                    \"Model_Error_(Residual)\": volumes_for_viz[\"Model_Error_(Residual)\"],\n",
    "                })\n",
    "                visualizations_log[\"3D/Tier1_Downsampled\"] = wandb.Plotly(ds_fig)\n",
    "\n",
    "                cr_fig = create_cropped_comparison({\n",
    "                    \"Predicted_Karst_(X_pred)\": volumes_for_viz[\"Predicted_Karst_(X_pred)\"],\n",
    "                    \"Forward_Model_Seismic_(Y_pred)\": volumes_for_viz[\"Forward_Model_Seismic_(Y_pred)\"],\n",
    "                    \"Model_Error_(Residual)\": volumes_for_viz[\"Model_Error_(Residual)\"],\n",
    "                })\n",
    "                visualizations_log[\"3D/Tier2_Cropped\"] = wandb.Plotly(cr_fig)\n",
    "                '''\n",
    "                if bool(config.get(\"enable_high_fidelity_3d\", True)):\n",
    "                    visualizations_log[\"Viz3D/PyVista_Renders/AI_Prediction\"] = wandb.Html(\n",
    "                        create_pyvista_render(volumes_for_viz[\"Predicted_Karst_(X_pred)\"], \"PV_Prediction\")\n",
    "                    )\n",
    "                    visualizations_log[\"Viz3D/PyVista_Renders/Model_Error\"] = wandb.Html(\n",
    "                        create_pyvista_render(volumes_for_viz[\"Model_Error_(Residual)\"], \"PV_Error\")\n",
    "                    )\n",
    "\n",
    "                if bool(config.get(\"enable_ipyvolume\", False)):\n",
    "                    visualizations_log[\"Viz3D/ipyvolume_Renders/AI_Prediction\"] = wandb.Html(\n",
    "                        create_ipyvolume_render(volumes_for_viz[\"Predicted_Karst_(X_pred)\"], \"IPV_Prediction\")\n",
    "                    )\n",
    "                    visualizations_log[\"Viz3D/ipyvolume_Renders/Model_Error\"] = wandb.Html(\n",
    "                        create_ipyvolume_render(volumes_for_viz[\"Model_Error_(Residual)\"], \"IPV_Error\")\n",
    "                    )\n",
    "\n",
    "            # Prepare data for logging (2D slices, logs, etc.)\n",
    "            # Single-channel rendering: we use the scalar volume (or channel 0) for slices.\n",
    "            # Multi-channel is feasible later by indexing and looping channels.\n",
    "            slice_idx = sample['seismic'].shape[2] // 2\n",
    "            seismic_slice = sample['seismic'][:, :, slice_idx]\n",
    "            gt_slice = sample['karst'][:, :, slice_idx]\n",
    "            pred_slice = prediction_3d[:, :, slice_idx]\n",
    "            residual_slice = pred_slice - gt_slice\n",
    "            max_abs_val = np.max(np.abs(residual_slice))\n",
    "            residual_norm = (residual_slice + max_abs_val) / (2 * max_abs_val) if max_abs_val > 0 else np.zeros_like(residual_slice)\n",
    "\n",
    "            # Per-epoch 2D diagnostic: compact 2x2 central-slice grid for one representative sample (single-channel).\n",
    "            if sample['sample_id'] == fixed_samples[0]['sample_id']:\n",
    "                grid_top = np.hstack([\n",
    "                    normalize_for_visualization(seismic_slice),  # Y\n",
    "                    normalize_for_visualization(gt_slice)        # X\n",
    "                ])\n",
    "                grid_bottom = np.hstack([\n",
    "                    normalize_for_visualization(pred_slice),     # X_pred\n",
    "                    residual_norm                                # Residual (already normalized to 0..1 around 0)\n",
    "                ])\n",
    "                grid_img = np.vstack([grid_top, grid_bottom])\n",
    "\n",
    "                # Stable key (no epoch in the key): W&B will store history by step\n",
    "                visualizations_log[\"Viz/diagnostics/central_slice_grid\"] = wandb.Image(\n",
    "                    grid_img,\n",
    "                    caption=\"Top: Y, X | Bottom: X_pred, Residual\"\n",
    "                )\n",
    "\n",
    "                # Residual_Y (Y_pred - Y) at central x-slice (sagittal)\n",
    "                y_pred_slice = y_pred_3d[:, :, slice_idx]\n",
    "                residual_y_slice = y_pred_slice - seismic_slice\n",
    "                max_abs_val_y = float(np.max(np.abs(residual_y_slice)))\n",
    "                residual_y_norm = (residual_y_slice + max_abs_val_y) / (2.0 * max_abs_val_y) if max_abs_val_y > 0 else np.zeros_like(residual_y_slice)\n",
    "                visualizations_log[\"Viz/diagnostics/residual_Yslice\"] = wandb.Image(residual_y_norm, caption=\"Residual Y (Y_pred - Y), central sagittal slice\")\n",
    "\n",
    "                    # Orientation indices\n",
    "                z_mid = sample['seismic'].shape[0] // 2\n",
    "                y_mid = sample['seismic'].shape[1] // 2\n",
    "                x_mid = slice_idx  # already computed\n",
    "\n",
    "                # Helper to build a 2x2 grid for a given slicer\n",
    "                def _grid_from_slices(y2d, x2d, xpred2d, label=\"\"):\n",
    "                    res = xpred2d - x2d\n",
    "                    m = float(np.max(np.abs(res)))\n",
    "                    res_norm = (res + m) / (2.0 * m) if m > 0 else np.zeros_like(res)\n",
    "                    top = np.hstack([normalize_for_visualization(y2d), normalize_for_visualization(x2d)])\n",
    "                    bottom = np.hstack([normalize_for_visualization(xpred2d), res_norm])\n",
    "                    return np.vstack([top, bottom])\n",
    "\n",
    "                # Axial (constant z)\n",
    "                axial_grid = _grid_from_slices(\n",
    "                    sample['seismic'][z_mid, :, :],\n",
    "                    sample['karst'][z_mid, :, :],\n",
    "                    prediction_3d[z_mid, :, :],\n",
    "                    \"axial\",\n",
    "                )\n",
    "                visualizations_log[\"Viz/slices/axial_central\"] = wandb.Image(axial_grid, caption=\"Axial: Y, X | X_pred, Residual_X\")\n",
    "\n",
    "                # Coronal (constant y)\n",
    "                coronal_grid = _grid_from_slices(\n",
    "                    sample['seismic'][:, y_mid, :],\n",
    "                    sample['karst'][:, y_mid, :],\n",
    "                    prediction_3d[:, y_mid, :],\n",
    "                    \"coronal\",\n",
    "                )\n",
    "                visualizations_log[\"Viz/slices/coronal_central\"] = wandb.Image(coronal_grid, caption=\"Coronal: Y, X | X_pred, Residual_X\")\n",
    "\n",
    "                # Sagittal (constant x) — complements the existing central grid\n",
    "                sagittal_grid = _grid_from_slices(\n",
    "                    sample['seismic'][:, :, x_mid],\n",
    "                    sample['karst'][:, :, x_mid],\n",
    "                    prediction_3d[:, :, x_mid],\n",
    "                    \"sagittal\",\n",
    "                )\n",
    "                visualizations_log[\"Viz/slices/sagittal_central\"] = wandb.Image(sagittal_grid, caption=\"Sagittal: Y, X | X_pred, Residual_X\")\n",
    "\n",
    "                # XZ section at y_mid: Residual_Y (Y_pred - Y)\n",
    "                xz_residual_y = y_pred_3d[:, y_mid, :] - sample['seismic'][:, y_mid, :]\n",
    "                m_xz = float(np.max(np.abs(xz_residual_y)))\n",
    "                xz_residual_y_norm = (xz_residual_y + m_xz) / (2.0 * m_xz) if m_xz > 0 else np.zeros_like(xz_residual_y)\n",
    "                visualizations_log[\"Viz/sections/xz_central\"] = wandb.Image(xz_residual_y_norm, caption=\"XZ Residual Y (Y_pred - Y) @ y_mid\")\n",
    "\n",
    "                # YZ section at x_mid: Residual_Y (Y_pred - Y)\n",
    "                yz_residual_y = y_pred_3d[:, :, x_mid] - sample['seismic'][:, :, x_mid]\n",
    "                m_yz = float(np.max(np.abs(yz_residual_y)))\n",
    "                yz_residual_y_norm = (yz_residual_y + m_yz) / (2.0 * m_yz) if m_yz > 0 else np.zeros_like(yz_residual_y)\n",
    "                visualizations_log[\"Viz/sections/yz_central\"] = wandb.Image(yz_residual_y_norm, caption=\"YZ Residual Y (Y_pred - Y) @ x_mid\")\n",
    "\n",
    "                # Axial montage: 5 evenly spaced z-slices of Residual_X (X_pred - X)\n",
    "                nz = prediction_3d.shape[0]\n",
    "                z_indices = [int(round(p * (nz - 1))) for p in [0.2, 0.35, 0.5, 0.65, 0.8]]\n",
    "\n",
    "                def _norm_residual_x_at_z(z_idx):\n",
    "                    res = prediction_3d[z_idx, :, :] - sample['karst'][z_idx, :, :]\n",
    "                    m = float(np.max(np.abs(res)))\n",
    "                    return (res + m) / (2.0 * m) if m > 0 else np.zeros_like(res)\n",
    "\n",
    "                tiles = [_norm_residual_x_at_z(z) for z in z_indices]\n",
    "                axial_montage = np.hstack(tiles)  # single wide image for scrubber\n",
    "                visualizations_log[\"Viz/slices/axial_tiled_5z\"] = wandb.Image(axial_montage, caption=f\"Residual_X axial montage z={z_indices}\")\n",
    "            else:\n",
    "                # Same grid under a per-sample stable key\n",
    "                grid_top = np.hstack([\n",
    "                    normalize_for_visualization(seismic_slice),\n",
    "                    normalize_for_visualization(gt_slice)\n",
    "                ])\n",
    "                grid_bottom = np.hstack([\n",
    "                    normalize_for_visualization(pred_slice),\n",
    "                    residual_norm\n",
    "                ])\n",
    "                grid_img = np.vstack([grid_top, grid_bottom])\n",
    "\n",
    "                visualizations_log[f\"Viz/diagnostics/central_slice_grid/sample:{sample['sample_id']}\"] = wandb.Image(\n",
    "                    grid_img, caption=f\"Top: Y, X | Bottom: X_pred, Residual_X (sample {sample['sample_id']})\"\n",
    "                )\n",
    "            \n",
    "            # Metrics\n",
    "            reconstruction_mse = float(np.mean((pred_slice - gt_slice) ** 2))\n",
    "            condition_consistency_mse = float(np.mean((y_pred_3d - sample['seismic']) ** 2))\n",
    "            total_reconstruction_mse += reconstruction_mse\n",
    "            total_condition_consistency_mse += condition_consistency_mse\n",
    "            ssim_score = ssim(gt_slice, pred_slice, data_range=1.0)\n",
    "            \n",
    "            # Well Logs\n",
    "            well_log_depth = np.arange(prediction_3d.shape[0]) * 25\n",
    "            well_x, well_y = prediction_3d.shape[1] // 2, prediction_3d.shape[2] // 2\n",
    "            gt_well_log = sample['karst'][:, well_x, well_y]\n",
    "            pred_well_log = prediction_3d[:, well_x, well_y]\n",
    "            log_correlation = np.corrcoef(gt_well_log, pred_well_log)[0, 1] if np.std(gt_well_log) > 0 and np.std(pred_well_log) > 0 else 0.0\n",
    "            \n",
    "            # Add data to the validation table\n",
    "            validation_table.add_data(\n",
    "            epoch,\n",
    "            sample['sample_id'],\n",
    "            wandb.Image(normalize_for_visualization(seismic_slice)),\n",
    "            wandb.Image(normalize_for_visualization(gt_slice)),\n",
    "            wandb.Image(normalize_for_visualization(pred_slice)),\n",
    "            wandb.Image(residual_norm, caption=\"Residual Map\"),\n",
    "            plot_well_log_comparison(gt_well_log, pred_well_log, well_log_depth),\n",
    "            reconstruction_mse,                 # X_pred vs X (central slice)\n",
    "            condition_consistency_mse,          # Y_pred vs Y (full 3D)\n",
    "            ssim_score,\n",
    "            log_correlation\n",
    "            )\n",
    "\n",
    "        # Log validation metrics ONCE per epoch\n",
    "        # Log all epoch-level data in a single call\n",
    "        avg_recon = total_reconstruction_mse / len(fixed_samples)\n",
    "        avg_cond  = total_condition_consistency_mse / len(fixed_samples)\n",
    "\n",
    "        # Validation loss tied to actual validation metrics\n",
    "        val_total_loss = 0.45 * avg_recon + 0.55 * avg_cond\n",
    "        epoch_log_data = {\"val/total_loss\": val_total_loss, \"val/avg_reconstruction_mse\": total_reconstruction_mse / len(fixed_samples),\n",
    "        \"val/avg_condition_consistency_mse\": total_condition_consistency_mse / len(fixed_samples), \"val_table/validation_table\": validation_table}\n",
    "        epoch_log_data.update(visualizations_log) # Add the dictionary of 3D views\n",
    "        run.log(epoch_log_data)\n",
    "\n",
    "        # ===================================================================\n",
    "        # 5. W&B MODEL REGISTRY: Versioning Models as Artifacts\n",
    "        #    - We check if the model has improved and, if so, save it.\n",
    "        #    - wandb.Artifact() creates a versioned package of model files and metadata.\n",
    "        #    - run.link_artifact() registers the model in the W&B Model Registry,\n",
    "        #      assigning it an alias like \"best\" or \"staging\" for easy retrieval.\n",
    "        # ===================================================================\n",
    "        if val_total_loss < best_validation_loss:\n",
    "            best_validation_loss = val_total_loss\n",
    "            print(f\"New best model at epoch {epoch}! Validation loss: {val_total_loss:.4f}\")\n",
    "            \n",
    "            # Build a concise model card as markdown; this will render as the artifact/model “card”\n",
    "            model_card_md = dedent(f\"\"\"\\\n",
    "            # Model Card: Conditional Diffusion (Simulated)\n",
    "\n",
    "            ## Overview\n",
    "            - Task: Geological structure generation (conditional diffusion)\n",
    "            - Notation: X (GT karst), X_pred (generated), Y (seismic), Y_pred = f(X_pred), Residual = Y_pred − Y\n",
    "            - Demo visuals: single-channel; 3D at 0/mid/last; 2D grid every epoch\n",
    "\n",
    "            ## Data & Lineage\n",
    "            - Dataset artifact: `{artifact.name}`\n",
    "            - Validation samples: {len(fixed_samples)} (pre-validated)\n",
    "\n",
    "            ## Training Summary (this version)\n",
    "            - Epoch: {epoch}\n",
    "            - val/total_loss: {val_total_loss:.6f}\n",
    "            - val/avg_reconstruction_mse: {avg_recon:.6f}\n",
    "            - val/avg_condition_consistency_mse: {avg_cond:.6f}\n",
    "\n",
    "            ## Key Config\n",
    "            - epochs={config.get('epochs')}, batches_per_epoch={config.get('batches_per_epoch')}\n",
    "            - learning_rate={config.get('learning_rate')}, batch_size={config.get('batch_size')}\n",
    "            - noise_schedule={config.get('noise_schedule')}, conditioning_strength={config.get('conditioning_strength')}\n",
    "            - seed={config.get('seed')}\n",
    "\n",
    "            ## Limitations\n",
    "            - Simulated training and losses for reproducible demo\n",
    "            - Embedded 3D is downsampled for responsiveness\n",
    "            \"\"\").strip()\n",
    "            \n",
    "            checkpoint_artifact = wandb.Artifact(\n",
    "                name=\"conditional-diffusion-checkpoint\",\n",
    "                type=\"model\",\n",
    "                description=model_card_md,  # <- model card as markdown\n",
    "                metadata={\n",
    "                    \"epoch\": epoch,\n",
    "                    \"validation_loss\": round(val_total_loss, 4),\n",
    "                    \"dataset_artifact\": artifact.name\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            checkpoint_path = f\"best_model_epoch_{epoch}.pth\"\n",
    "            Path(checkpoint_path).write_text(f\"Best model checkpoint at epoch {epoch}\")\n",
    "            checkpoint_artifact.add_file(checkpoint_path)\n",
    "            \n",
    "            # Log the artifact and link it to the registry\n",
    "            logged_artifact = run.log_artifact(checkpoint_artifact, aliases=[\"best\"])\n",
    "           \n",
    "            # run.link_artifact() registers the model in the W&B Model Registry. Aliases\n",
    "            # like \"staging\" or \"production\" create pointers for CI/CD systems, automating\n",
    "            # the path from training to deployment.\n",
    "            run.link_artifact(\n",
    "                artifact=logged_artifact,\n",
    "                target_path=\"wandb-registry-model/conditional-diffusion\",\n",
    "                aliases=[\"staging\"]\n",
    "            )\n",
    "            os.remove(checkpoint_path)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6. W&B CLEANUP: Finalizing the Run\n",
    "    #    - run.finish() marks the run as complete and uploads any remaining data.\n",
    "    # ===================================================================\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5ad2f",
   "metadata": {},
   "source": [
    "## 4. Execute a Single Training Run\n",
    "\n",
    "Run a baseline training to generate live metrics, validation media, and a versioned model artifact.\n",
    "\n",
    "- What this does\n",
    "  - Starts a W&B run with your config and tags\n",
    "  - Streams training metrics; correlates with system telemetry\n",
    "  - Logs per‑epoch validation media:\n",
    "    - `Viz/diagnostics/central_slice_grid` (2D: Y, X, X_pred, Residual)\n",
    "    - Optional 3D Html (0 / mid / last) when `enable_3d=True` and `enable_high_fidelity_3d=True`\n",
    "  - Tracks best validation loss and versions a checkpoint artifact; links it in the Model Registry (e.g., alias `staging`)\n",
    "\n",
    "- Where to look in W&B\n",
    "  - Run Overview: metrics and config\n",
    "  - System: CPU/memory correlated with metrics\n",
    "  - Media: `Viz/diagnostics/central_slice_grid`, `Viz/PyVista_Renders/*` (if 3D enabled)\n",
    "  - Tables: `val_table/validation_table` (images + well‑log Plotly Html)\n",
    "  - Artifacts/Registry: `conditional-diffusion-checkpoint` with alias\n",
    "\n",
    "- Why W&B here\n",
    "  - Live metrics + rich media + artifacts in one place, with lineage and aliases for governance\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Run the cell; click the “View run” link\n",
    "  - [ ] Expand rows in `val_table/validation_table` to inspect media\n",
    "  - [ ] If 3D is enabled, open `Viz/PyVista_Renders/*` at epochs 0 / mid / last\n",
    "  - [ ] Locate the model artifact and verify its registry alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddae711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_194833-9en99mgu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/9en99mgu' target=\"_blank\">lunar-galaxy-1</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/9en99mgu' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/9en99mgu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8425\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7808\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7267\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.6818\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>██████████████▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>██████▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/reconstruction_mse</td><td>█████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/total_loss</td><td>████████▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▅▃▁▂▂▂▇▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▆▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▅▃▁▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>0.00086</td></tr><tr><td>train/noise_prediction_loss</td><td>0.48049</td></tr><tr><td>train/reconstruction_mse</td><td>0.13947</td></tr><tr><td>train/total_loss</td><td>0.34408</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38225</td></tr><tr><td>val/avg_reconstruction_mse</td><td>8e-05</td></tr><tr><td>val/total_loss</td><td>0.76028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-galaxy-1</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/9en99mgu' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/9en99mgu</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 116 media file(s), 127 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_194833-9en99mgu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with default config\n",
    "# Use the example config we defined earlier \n",
    "train_conditional_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12db70",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Sweeps: Enterprise-Scale Optimization\n",
    "\n",
    "Running one experiment manually is not efficient. To find the optimal model, we explore the hyperparameter space using W&B Sweeps.\n",
    "\n",
    "- What this does\n",
    "  - Defines a Bayesian sweep optimizing `val/total_loss`\n",
    "  - Enables early termination via Hyperband (iteration == epoch)\n",
    "    - `min_iter=3`: allow a few epochs before pruning\n",
    "    - `max_iter=6`: aligns with the demo’s total epochs\n",
    "    - `eta=3`: keep strongest ~1/3 at each bracket\n",
    "  - Keeps sweeps fast by disabling 3D (`enable_3d=False`, `enable_high_fidelity_3d=False`, `enable_ipyvolume=False`)\n",
    "  - Creates the sweep controller in the W&B cloud and returns a `sweep_id`\n",
    "\n",
    "- Where to look in W&B\n",
    "  - Sweeps page: centralized view of runs, pruning, and best configs\n",
    "  - Run pages: each trial’s metrics, media (2D only in sweeps), and config\n",
    "\n",
    "- Why W&B here\n",
    "  - Built-in orchestration and visual comparisons reduce custom tooling\n",
    "  - Early termination saves compute by stopping weak configs mid-training\n",
    "\n",
    "- Notes\n",
    "  - Agents derive project/entity from the sweep and may print “Ignoring project/entity” when starting; this is expected.\n",
    "  - Keep runs short in demos (few epochs) to get visible results quickly.\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Adjust the search space (e.g., widen `conditioning_strength`)\n",
    "  - [ ] Re-create the sweep and note the new `sweep_id`\n",
    "  - [ ] Open the Sweeps page and watch trials/pruning in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b17e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-5' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6c2jgzy1\n",
      "Sweep URL: https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1\n",
      "✅ Sweep created successfully! Sweep ID: 6c2jgzy1\n",
      "🧹 View and manage your sweep here: https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1\n"
     ]
    }
   ],
   "source": [
    "# Early termination: realistic Hyperband settings for epoch-based training\n",
    "# - Iteration == epoch (we log val/total_loss once per epoch)\n",
    "# - min_iter: let every run complete at least the first 3 epochs before pruning\n",
    "# - max_iter: equal to total epochs per run (6 here). If you raise epochs, raise this too\n",
    "# - eta: 3 means keep roughly the top 1/3 at each bracket; 2 is gentler, 4 is more aggressive\n",
    "# - Effect: poor configs get stopped around mid-training; strong configs run to completion\n",
    "early_stop = {\"type\": \"hyperband\", \"min_iter\": 3, \"max_iter\": 6, \"eta\": 3}\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val/total_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "    \"learning_rate\": {\"distribution\": \"log_uniform_values\", \"min\": 1e-5, \"max\": 3e-2},\n",
    "    \"batch_size\": {\"values\": [2, 4, 8, 16]},\n",
    "    \"noise_schedule\": {\"values\": [\"cosine\", \"linear\", \"sigmoid\"]},\n",
    "    \"conditioning_strength\": {\"distribution\": \"uniform\", \"min\": 0.45, \"max\": 1.0},\n",
    "\n",
    "    \"epochs\": {\"value\": 10},\n",
    "    \"batches_per_epoch\": {\"value\": 20},\n",
    "    \"seed\": {\"values\": [41, 42, 43]},\n",
    "\n",
    "    \"enable_3d\": {\"value\": False},\n",
    "    \"enable_high_fidelity_3d\": {\"value\": False},\n",
    "    \"enable_ipyvolume\": {\"value\": False}\n",
    "},\n",
    "   # This is commented out as it serves no purpose in this workshop but can be useful for real-world training\n",
    "   # \"early_terminate\": early_stop,\n",
    "}\n",
    "# 2. Initialize the Sweep\n",
    "# This command creates the sweep controller in the W&B cloud. It acts as a\n",
    "# central coordinator that agents can query for new jobs.\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config,\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT\n",
    ")\n",
    "\n",
    "print(f\"✅ Sweep created successfully! Sweep ID: {sweep_id}\")\n",
    "print(f\"🧹 View and manage your sweep here: https://wandb.ai/{ENTITY}/{PROJECT}/sweeps/{sweep_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07322a0",
   "metadata": {},
   "source": [
    "## 6. Launch a W&B Agent\n",
    "\n",
    "Now that the sweep is initialized, launch an agent. The agent is a stateless worker that will:\n",
    "1) Request a hyperparameter set from the sweep controller  \n",
    "2) Invoke your training function (`function=train_conditional_diffusion`) with no positional arguments  \n",
    "3) Inside the function, `wandb.init()` receives the sweep-provided config; access it via `wandb.config`  \n",
    "4) Report results and request a new job until the sweep ends\n",
    "\n",
    "- What this does\n",
    "  - Starts an agent that executes N trials (`count`) from the sweep\n",
    "  - Uses the sweep’s metric (`val/total_loss`) for early termination\n",
    "  - Disables 3D per the sweep config for speed (`enable_3d=False`, `enable_high_fidelity_3d=False`, `enable_ipyvolume=False`)\n",
    "\n",
    "- How pruning works here\n",
    "  - The sweep’s metric is `val/total_loss`, logged once per epoch\n",
    "  - “Iterations” for Hyperband equal the number of times that metric is logged (i.e., epochs here)\n",
    "  - `min_iter`/`max_iter` therefore map to epoch counts for pruning  \n",
    "    (See docs: early termination brackets are based on the count of the optimized metric logs, not global step)\n",
    "\n",
    "- Where to look in W&B\n",
    "  - Sweeps page: view active/finished trials, pruning, and best configs\n",
    "  - Each run page: trial metrics, config, and media (2D only during sweeps)\n",
    "\n",
    "- Notes\n",
    "  - Console may show “Ignoring project/entity” when running a sweep; this is expected (agents inherit from the sweep)\n",
    "  - Keep `count` small for demos to finish quickly; raise later for broader search\n",
    "  - Stop the agent with the notebook’s interrupt if needed\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Run the agent for a few trials (e.g., `count=5`)\n",
    "  - [ ] Observe pruning as weak configs stop earlier\n",
    "  - [ ] Open the best run from the Sweeps page and compare configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d44a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vft570iz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches_per_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconditioning_strength: 0.8810594491932708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_high_fidelity_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_ipyvolume: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00016897362920980895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_schedule: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mallanstevenson\u001b[0m (\u001b[33mwandb_emea\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'workshop-ex123456789' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'wandb_emea' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_194953-vft570iz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/vft570iz' target=\"_blank\">ancient-sweep-1</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/vft570iz' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/vft570iz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8477\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7792\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7228\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.6759\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>██████████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>██████████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▁▁</td></tr><tr><td>train/reconstruction_mse</td><td>████████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▄▄▃▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/total_loss</td><td>██████████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▄▃▃▃▃▃▃▃▁▁▁▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▅▃▁▃▃▃▇▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▆▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▅▃▁▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>0.00014</td></tr><tr><td>train/noise_prediction_loss</td><td>0.71495</td></tr><tr><td>train/reconstruction_mse</td><td>0.16439</td></tr><tr><td>train/total_loss</td><td>0.49473</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38226</td></tr><tr><td>val/avg_reconstruction_mse</td><td>9e-05</td></tr><tr><td>val/total_loss</td><td>0.76028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-1</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/vft570iz' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/vft570iz</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 110 media file(s), 119 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_194953-vft570iz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0w8o0xjz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches_per_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconditioning_strength: 0.4804638063221182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_high_fidelity_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_ipyvolume: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000560502678787149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_schedule: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 43\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-12' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'workshop-ex123456789' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'wandb_emea' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_195035-0w8o0xjz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/0w8o0xjz' target=\"_blank\">gentle-sweep-2</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/0w8o0xjz' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/0w8o0xjz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8447\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7988\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7516\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.7154\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "New best model at epoch 4! Validation loss: 0.6872\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "New best model at epoch 5! Validation loss: 0.6866\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>██████████▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>██████████▇█▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/reconstruction_mse</td><td>██████████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/total_loss</td><td>████████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▂▂▁▁▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▆▄▂▁▁▁▆▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▇▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▆▄▂▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>0.00048</td></tr><tr><td>train/noise_prediction_loss</td><td>0.81044</td></tr><tr><td>train/reconstruction_mse</td><td>0.2296</td></tr><tr><td>train/total_loss</td><td>0.57811</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38042</td></tr><tr><td>val/avg_reconstruction_mse</td><td>0.00016</td></tr><tr><td>val/total_loss</td><td>0.7593</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-sweep-2</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/0w8o0xjz' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/0w8o0xjz</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 110 media file(s), 123 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_195035-0w8o0xjz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qopt0wkn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches_per_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconditioning_strength: 0.5014788284786833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_high_fidelity_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_ipyvolume: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.521889560306934e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_schedule: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-19' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'workshop-ex123456789' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'wandb_emea' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_195139-qopt0wkn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/qopt0wkn' target=\"_blank\">scarlet-sweep-3</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/qopt0wkn' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/qopt0wkn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8424\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7954\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7520\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.7134\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "New best model at epoch 4! Validation loss: 0.6873\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "New best model at epoch 5! Validation loss: 0.6866\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>██████████████▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>████████▇▇▇▇▇▇▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▁</td></tr><tr><td>train/reconstruction_mse</td><td>████████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/total_loss</td><td>█████████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▂▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▆▄▂▁▁▁▆▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▆▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▆▄▂▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/noise_prediction_loss</td><td>0.82877</td></tr><tr><td>train/reconstruction_mse</td><td>0.23225</td></tr><tr><td>train/total_loss</td><td>0.59017</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38057</td></tr><tr><td>val/avg_reconstruction_mse</td><td>0.00014</td></tr><tr><td>val/total_loss</td><td>0.75938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-3</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/qopt0wkn' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/qopt0wkn</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 110 media file(s), 119 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_195139-qopt0wkn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pya7ad99 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches_per_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconditioning_strength: 0.456685258855234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_high_fidelity_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_ipyvolume: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004068509889883103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_schedule: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'workshop-ex123456789' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'wandb_emea' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_195224-pya7ad99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/pya7ad99' target=\"_blank\">worthy-sweep-4</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/pya7ad99' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/pya7ad99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!ownloaded...\n",
      "task: <Task pending name='Task-26' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8447\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7999\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7536\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.7182\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "New best model at epoch 4! Validation loss: 0.6873\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "New best model at epoch 5! Validation loss: 0.6867\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>███████████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁</td></tr><tr><td>train/noise_prediction_loss</td><td>███████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▂▂▁▁▁</td></tr><tr><td>train/reconstruction_mse</td><td>████████▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/total_loss</td><td>██████████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▆▄▂▁▁▁▆▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▇▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▆▄▂▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>0.00035</td></tr><tr><td>train/noise_prediction_loss</td><td>0.82217</td></tr><tr><td>train/reconstruction_mse</td><td>0.23838</td></tr><tr><td>train/total_loss</td><td>0.58866</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38017</td></tr><tr><td>val/avg_reconstruction_mse</td><td>0.00018</td></tr><tr><td>val/total_loss</td><td>0.75917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-4</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/pya7ad99' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/pya7ad99</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 110 media file(s), 119 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_195224-pya7ad99/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jl5tji2l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches_per_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconditioning_strength: 0.4576413774041321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_high_fidelity_3d: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenable_ipyvolume: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00045482625942300887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_schedule: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 43\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-33' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'workshop-ex123456789' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'wandb_emea' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250812_195310-jl5tji2l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/jl5tji2l' target=\"_blank\">rosy-sweep-5</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/sweeps/6c2jgzy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/jl5tji2l' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/jl5tji2l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   97 of 97 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 0.8447\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.7999\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.7535\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.7181\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "New best model at epoch 4! Validation loss: 0.6873\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "New best model at epoch 5! Validation loss: 0.6867\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>██████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>███████████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▁</td></tr><tr><td>train/reconstruction_mse</td><td>██████████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train/total_loss</td><td>█████████████▇▇▇▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>█▆▄▂▁▁▁▆▇▇</td></tr><tr><td>val/avg_reconstruction_mse</td><td>█▇▅▄▂▂▂▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▆▄▂▁▁▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learning_rate</td><td>0.00039</td></tr><tr><td>train/noise_prediction_loss</td><td>0.82031</td></tr><tr><td>train/reconstruction_mse</td><td>0.23697</td></tr><tr><td>train/total_loss</td><td>0.58697</td></tr><tr><td>val/avg_condition_consistency_mse</td><td>1.38018</td></tr><tr><td>val/avg_reconstruction_mse</td><td>0.00018</td></tr><tr><td>val/total_loss</td><td>0.75918</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-5</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789/runs/jl5tji2l' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789/runs/jl5tji2l</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-ex123456789' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-ex123456789</a><br>Synced 8 W&B file(s), 110 media file(s), 119 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250812_195310-jl5tji2l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Run the Sweep Agent\n",
    "# This single command connects a worker to the sweep controller. The agent\n",
    "# automatically fetches a configuration, executes the training function,\n",
    "# and reports the results back, requiring zero manual orchestration.\n",
    "wandb.agent(sweep_id, function=train_conditional_diffusion, count=5)\n",
    "wandb.teardown() # if we want to do normal runs after a sweep, in the same session, we must run this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b8187",
   "metadata": {},
   "source": [
    "## 7. Programmatic Executive Reports: From Model to Boardroom\n",
    "\n",
    "The final step is to bridge the gap between technical results and business stakeholders. This section shows how to generate a data‑driven executive report directly from your experiments—kept in sync with the project’s best run.\n",
    "\n",
    "- What this does\n",
    "  - Identifies the best finished run by `val/total_loss`\n",
    "  - Builds a report with headline KPIs, a validation loss chart, and the per‑epoch validation table\n",
    "  - Publishes a shareable link that always points at the latest, programmatically generated summary\n",
    "\n",
    "- Where to look in W&B\n",
    "  - Reports: the generated report appears under the project’s Reports tab\n",
    "  - Linked Run: the report references the best run and its media/table\n",
    "  - Tables Panel: uses the logged `val_table/validation_table` from the best run\n",
    "\n",
    "- Why W&B here\n",
    "  - Stakeholder‑ready, parameterized reports reduce ad‑hoc slide work and stay in sync with the source of truth\n",
    "  - Reports blend metrics, media, and tables—with live links back to runs, artifacts, and registry items\n",
    "\n",
    "- Try it yourself\n",
    "  - [ ] Run at least one training to produce finished runs with `val/total_loss`\n",
    "  - [ ] Execute the report cell; open the printed URL\n",
    "  - [ ] Share the link with SMEs; it updates as new best runs are produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06cc5105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a programmatic report...\n",
      "Using entity: 'wandb_emea', project: 'workshop-ex123456789'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-40' coro=<Event.wait() running at /opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/locks.py:214> wait_for=<Future cancelled>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report based on best run: worthy-sweep-4 (ID: pya7ad99)\n",
      "Best validation loss: 0.7592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Saved report to: https://wandb.ai/wandb_emea/workshop-ex123456789/reports/Geological-ML-Model-Performance---2025-08-12--VmlldzoxMzk2ODYwMw==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report created successfully!\n",
      "Title: Geological ML Model Performance - 2025-08-12\n",
      "URL: https://wandb.ai/wandb_emea/workshop-ex123456789/reports/Geological-ML-Model-Performance---2025-08-12--VmlldzoxMzk2ODYwMw==\n",
      "This script could be extended to leverage a Teams webhook to send a notification to a channel\n"
     ]
    }
   ],
   "source": [
    "# Programmatic report without Markdown formatting in text blocks\n",
    "import time\n",
    "import wandb\n",
    "import wandb_workspaces.reports.v2 as wr\n",
    "\n",
    "print(\"Creating a programmatic report...\")\n",
    "print(f\"Using entity: '{ENTITY}', project: '{PROJECT}'\")\n",
    "\n",
    "try:\n",
    "    # 1) Find the best finished run by val/total_loss\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(\n",
    "        path=f\"{ENTITY}/{PROJECT}\",\n",
    "        order=\"-created_at\",\n",
    "        filters={\"tags\": \"conditional-diffusion\", \"state\": \"finished\"},\n",
    "    )\n",
    "    if not runs:\n",
    "        raise ValueError(\"No finished runs with tag 'conditional-diffusion' found.\")\n",
    "\n",
    "    best_run = sorted(\n",
    "        runs, key=lambda r: r.summary.get(\"val/total_loss\", float(\"inf\"))\n",
    "    )[0]\n",
    "    best_val = best_run.summary.get(\"val/total_loss\", None)\n",
    "    best_val_str = f\"{best_val:.4f}\" if best_val is not None else \"N/A\"\n",
    "    print(f\"Generating report based on best run: {best_run.name} (ID: {best_run.id})\")\n",
    "    if best_val is not None:\n",
    "        print(f\"Best validation loss: {best_val_str}\")\n",
    "\n",
    "    # 2) Build the report container (full-width page)\n",
    "    report = wr.Report(\n",
    "        entity=ENTITY,\n",
    "        project=PROJECT,\n",
    "        title=f\"Geological ML Model Performance - {time.strftime('%Y-%m-%d')}\",\n",
    "        description=f\"Automated summary for the conditional diffusion model. Best run: {best_run.name}.\",\n",
    "        width=\"fluid\",\n",
    "    )\n",
    "\n",
    "    # Target the best run only\n",
    "    runset = wr.Runset(entity=ENTITY, project=PROJECT, name=best_run.id)\n",
    "\n",
    "    # 3) Blocks (plain text; no Markdown formatting)\n",
    "    report.blocks = [\n",
    "        wr.H1(\"Executive Summary: Geological Interpretation Model\"),\n",
    "        wr.P(\n",
    "            f\"The model was trained for {best_run.config.get('epochs', 'N/A')} epochs, \"\n",
    "            f\"achieving a final validation loss of {best_val_str}. \"\n",
    "            f\"This automated report was generated on {time.strftime('%B %d, %Y')}.\"\n",
    "        ),\n",
    "\n",
    "        wr.H2(\"Key Performance Metrics\"),\n",
    "        wr.P(\"Validation loss over time (X axis uses Step).\"),\n",
    "\n",
    "        wr.PanelGrid(\n",
    "            runsets=[runset],\n",
    "            panels=[\n",
    "                wr.LinePlot(\n",
    "                    title=\"Validation Loss Over Training\",\n",
    "                    y=[\"val/total_loss\"],\n",
    "                    layout={\"w\": 24, \"h\": 12},\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "        wr.PanelGrid(\n",
    "            runsets=[runset],\n",
    "            panels=[\n",
    "                wr.ScalarChart(\n",
    "                title=\"Best Final Validation Loss\",\n",
    "                metric=\"val/total_loss\",\n",
    "                layout={\"w\": 8, \"h\": 8},\n",
    "                ),\n",
    "                wr.ScalarChart(\n",
    "                    title=\"Best Avg Reconstruction MSE\",\n",
    "                    metric=\"val/avg_reconstruction_mse\",\n",
    "                    layout={\"w\": 8, \"h\": 8},\n",
    "                ),\n",
    "                wr.ScalarChart(\n",
    "                    title=\"Best Condition-Consistency MSE\",\n",
    "                    metric=\"val/avg_condition_consistency_mse\",\n",
    "                    layout={\"w\": 8, \"h\": 8},\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "        wr.H2(\"Detailed Validation Analysis\"),\n",
    "        wr.P(\"Interactive table logged each epoch; single-channel slices and well-log comparison.\"),\n",
    "\n",
    "        wr.PanelGrid(\n",
    "            runsets=[runset],\n",
    "            panels=[\n",
    "                wr.WeavePanelSummaryTable(\n",
    "                    table_name=\"val_table/validation_table\",\n",
    "                    layout={\"w\": 24, \"h\": 20},\n",
    "                )\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "        wr.H2(\"Model Governance and Next Steps\"),\n",
    "        wr.P(\"The best model artifact from this run has been versioned and linked to the Model Registry.\"),\n",
    "        wr.P(f\"Best model run: {best_run.name} ({best_run.id})\"),\n",
    "        wr.P([\"Run URL: \",wr.Link(f\"https://wandb.ai/{ENTITY}/{PROJECT}/runs/{best_run.id}\", url=f\"https://wandb.ai/{ENTITY}/{PROJECT}/runs/{best_run.id}\")]),\n",
    "        wr.P(\"Dataset artifact version: CigKarst:v0\"),\n",
    "        wr.P(\"Model artifact name: conditional-diffusion-checkpoint\"),\n",
    "        wr.P(\"Current registry alias: staging\"),\n",
    "        wr.P(\"Next steps:\"),\n",
    "        wr.P(\"1) Review model performance with geological subject matter experts.\"),\n",
    "        wr.P(\"2) Promote the model from Staging to Production if acceptance criteria are met.\"),\n",
    "        wr.P(\"3) Plan deployment to a validation environment.\"),\n",
    "    ]\n",
    "\n",
    "    report.save()\n",
    "    print(\"\\nReport created successfully!\")\n",
    "    print(f\"Title: {report.title}\")\n",
    "    print(f\"URL: {report.url}\")\n",
    "    print(\"This script could be extended to leverage a Teams webhook to send a notification to a channel\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Report creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93963204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5285b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7844ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16aa64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
