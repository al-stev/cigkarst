{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d86248e",
   "metadata": {},
   "source": [
    "# W&B Enterprise Workshop: Advanced Geological AI\n",
    "\n",
    "Welcome to the W&B Enterprise Workshop. In this session, we will demonstrate how Weights & Biases serves as the indispensable **system of record** for a complex, enterprise-grade machine learning workflow. By establishing a centralized hub for all our activities, we can break down silos between geoscientists, ML engineers, and stakeholders, creating a single source of truth for the entire project lifecycle.\n",
    "\n",
    "We will simulate the training of a **conditional diffusion model** for geological structure generation. This allows us to focus on the MLOps challenges—collaboration, monitoring, governance, and reporting—that W&B is designed to solve, without waiting hours for a real model to train.\n",
    "\n",
    "Our first step is to install the required libraries and import our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cef1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install minimal dependencies for W&B workshop\n",
    "# The wandb-workspaces library is key for both programmatic workspaces and reporting\n",
    "# allowing us to automatically generate stakeholder-ready W&B Reports later\n",
    "%pip install wandb numpy tqdm wandb-workspaces plotly pillow scikit-image pyvista ipyvolume ipython-genutils -q\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "import wandb_workspaces.reports.v2 as wr\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# New imports for 3D visualization\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pyvista as pv\n",
    "import ipyvolume as ipv\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Set PyVista to use an off-screen plotter for notebook environments\n",
    "pv.set_jupyter_backend(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417631e",
   "metadata": {},
   "source": [
    "## 1. W&B Project Configuration\n",
    "\n",
    "Here, we'll log in to W&B and define the `ENTITY` (your team or organization) and the `PROJECT` for this workshop. \n",
    "\n",
    "A W&B Project is a collaborative workspace where your entire team—from geoscientists to ML engineers—can track experiments, compare results, and share insights in real-time.\n",
    "\n",
    "Centralizing our work here is the first step toward building a reliable system of record. We also define a sample configuration dictionary that holds our model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2215955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mallanstevenson\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Authentication: Entity = wandb_emea\n",
      "Project: workshop-scratchpad\n",
      "Training configuration loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ENTITY = \"wandb_emea\"  # Replace with your W&B team entity\n",
    "PROJECT = \"workshop-scratchpad\"\n",
    "\n",
    "# Ensure you have logged in and defined ENTITY and PROJECT in a previous cell\n",
    "assert \"ENTITY\" in locals(), \"Please define the ENTITY variable\"\n",
    "assert \"PROJECT\" in locals(), \"Please define the PROJECT variable\"\n",
    "\n",
    "# W&B Team Authentication\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "print(f\"W&B Authentication: Entity = {ENTITY}\")\n",
    "print(f\"Project: {PROJECT}\")\n",
    "\n",
    "# Configuration for (simulated) conditional diffusion training\n",
    "# wandb.config makes hyperparameters a first-class citizen.\n",
    "# They are saved with every run, ensuring 100% reproducibility and\n",
    "# enabling powerful, automated hyperparameter sweeps\n",
    "\n",
    "example_config = {\n",
    "    # Model Architecture\n",
    "    \"model_architecture\": \"ConditionalUNet3D\",\n",
    "    \"task\": \"geological_structure_generation\",\n",
    "    \"input_modality\": \"seismic_amplitude\",\n",
    "    \"output_modality\": \"karst_structures\",\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"epochs\": 10,\n",
    "    \"batches_per_epoch\": 20,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 4,\n",
    "    \n",
    "    # Diffusion Parameters\n",
    "    \"timesteps\": 1000,\n",
    "    \"noise_schedule\": \"cosine\",\n",
    "    \"conditioning_strength\": 0.8,\n",
    "    \n",
    "    # Geological Domain\n",
    "    \"voxel_resolution\": \"25m\",\n",
    "    \"depth_range\": \"0-800m\",\n",
    "    \"geological_context\": \"karst_detection\"\n",
    "}\n",
    "\n",
    "print(\"Training configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4deb684",
   "metadata": {},
   "source": [
    "## 2. Simulation and Visualization Helpers\n",
    "\n",
    "This cell contains the helper functions for our workshop. **This is not part of the core W&B integration.**\n",
    "\n",
    "- `simulate_...`: A function that mimics the behavior of a real conditional diffusion model, generating progressively better geological predictions with each epoch.\n",
    "- `plot_...` & `normalize_...`: Utilities for creating interactive charts and preparing images for visualization.\n",
    "\n",
    "We're using a simulation because these generative models can run for days or weeks. By focusing on the MLOps workflow, we demonstrate how to solve the operational challenges—like monitoring, debugging, and reporting—where teams lose the most time and money, especially when long-running jobs fail silently.\n",
    "\n",
    "By isolating this simulation logic, we can focus the rest of the notebook purely on the MLOps workflow powered by W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d86083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By returning a wandb.Html object, we can log custom, interactive visualizations\n",
    "# like this Plotly chart directly into the W&B dashboard. This allows domain experts\n",
    "# to analyze results without switching contexts or downloading files.\n",
    "def plot_well_log_comparison(gt_log: np.ndarray, pred_log: np.ndarray, depth: np.ndarray) -> wandb.Html:\n",
    "    \"\"\"Creates an interactive Plotly chart comparing ground truth and predicted well logs.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=gt_log, y=depth, mode='lines', name='Ground Truth Log', line=dict(color='black')))\n",
    "    fig.add_trace(go.Scatter(x=pred_log, y=depth, mode='lines', name='Predicted Log', line=dict(color='crimson', dash='dash')))\n",
    "    fig.update_layout(\n",
    "        title=\"Well Log Comparison\",\n",
    "        xaxis_title=\"Signal Amplitude\",\n",
    "        yaxis_title=\"Depth (m)\",\n",
    "        yaxis_autorange='reversed' # Depth increases downwards\n",
    "    )\n",
    "    html = pio.to_html(fig)\n",
    "    return wandb.Html(html)\n",
    "\n",
    "def generate_synthetic_loss(step: int) -> float:\n",
    "    \"\"\"Generate realistic MSE loss that improves over time.\"\"\"\n",
    "    np.random.seed(int(step))\n",
    "    base_loss = 1.5 * np.exp(-step / 150.0) + 0.05\n",
    "    noise = np.random.normal(0, 0.02)\n",
    "    return max(0.01, base_loss + noise)\n",
    "\n",
    "def simulate_conditional_diffusion_progress(seismic_condition: np.ndarray, karst_target: np.ndarray, epoch: int, total_epochs: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate realistic conditional diffusion model learning progression.\n",
    "    Early epochs: noisy predictions with some seismic influence\n",
    "    Later epochs: cleaner karst structures conditioned on seismic input\n",
    "    \"\"\"\n",
    "    # Training progress (0.0 at start, 1.0 at end)\n",
    "    progress = epoch / (total_epochs - 1)\n",
    "\n",
    "    # Set deterministic seed based on epoch for reproducible progression\n",
    "    np.random.seed(epoch * 42)\n",
    "\n",
    "    # Stage 1 (epochs 0-3): Learning basic seismic-karst correlations\n",
    "    if epoch <= 3:\n",
    "        # Start with mostly noise, gradually incorporate seismic patterns\n",
    "        noise_level = 0.8 - (epoch / 3) * 0.4  # 0.8 → 0.4\n",
    "        structural_learning = epoch / 3 * 0.3   # 0.0 → 0.3\n",
    "\n",
    "        # Generate structural noise that respects seismic boundaries\n",
    "        structure_mask = (seismic_condition > np.percentile(seismic_condition, 60)).astype(float)\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        # Prediction combines noise with emerging structural understanding\n",
    "        prediction = (noise * 0.7 +\n",
    "                     seismic_condition * structural_learning +\n",
    "                     karst_target * structure_mask * 0.1)\n",
    "\n",
    "    # Stage 2 (epochs 4-6): Refining geological structures\n",
    "    elif epoch <= 6:\n",
    "        stage_progress = (epoch - 4) / 2  # 0.0 → 1.0 for epochs 4-6\n",
    "\n",
    "        # Better geological understanding - focus on karst-forming regions\n",
    "        karst_regions = (seismic_condition > np.percentile(seismic_condition, 40)) & (seismic_condition < np.percentile(seismic_condition, 85))\n",
    "\n",
    "        # Noise reduces significantly\n",
    "        noise_level = 0.4 - stage_progress * 0.25  # 0.4 → 0.15\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        # Geological structure emergence\n",
    "        geological_understanding = 0.3 + stage_progress * 0.4  # 0.3 → 0.7\n",
    "\n",
    "        prediction = (noise * 0.3 +\n",
    "                     karst_target * karst_regions * geological_understanding +\n",
    "                     seismic_condition * 0.2 * (1 - karst_regions))\n",
    "\n",
    "    # Stage 3 (epochs 7-9): Fine-tuning and detail refinement\n",
    "    else:\n",
    "        stage_progress = (epoch - 7) / 2  # 0.0 → 1.0 for epochs 7-9\n",
    "\n",
    "        # High geological accuracy with fine detail learning\n",
    "        noise_level = 0.15 - stage_progress * 0.10  # 0.15 → 0.05\n",
    "        noise = np.random.normal(0, noise_level, seismic_condition.shape)\n",
    "\n",
    "        # Near-target accuracy with realistic imperfections\n",
    "        accuracy = 0.7 + stage_progress * 0.25  # 0.7 → 0.95\n",
    "\n",
    "        # Add some realistic geological interpretation uncertainty\n",
    "        uncertainty_mask = np.random.random(seismic_condition.shape) < 0.1\n",
    "\n",
    "        prediction = (karst_target * accuracy +\n",
    "                     noise * 0.1 +\n",
    "                     seismic_condition * uncertainty_mask * 0.05)\n",
    "\n",
    "    # Ensure realistic value ranges\n",
    "    prediction = np.clip(prediction, 0, 1)\n",
    "    # Add a minuscule amount of noise to break mathematical perfection\n",
    "    # This ensures (prediction - ground_truth) is never exactly all zeros.\n",
    "    prediction += np.random.uniform(-1e-9, 1e-9, prediction.shape)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def normalize_for_visualization(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize geological data for W&B visualization with proper contrast.\"\"\"\n",
    "    data_min, data_max = np.min(data), np.max(data)\n",
    "    if data_max == data_min:\n",
    "        return np.full_like(data, 0.5)\n",
    "    normalized = (data - data_min) / (data_max - data_min)\n",
    "    # Apply gamma correction for better geological feature visibility\n",
    "    return np.power(normalized, 0.7)\n",
    "\n",
    "def simulate_forward_model(x_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulates a forward model y=f(x) to generate a predicted condition y_pred.\n",
    "    In a real scenario, this would be a physics-based or learned model.\n",
    "    Here, we simulate it by applying a slight blur and adding minor noise.\n",
    "    \"\"\"\n",
    "    # Apply a simple blurring effect (convolution with a small kernel)\n",
    "    kernel = np.ones((3, 3, 3)) / 27.0\n",
    "    # Use scipy for convolution if available, otherwise a simpler method\n",
    "    try:\n",
    "        from scipy.ndimage import convolve\n",
    "        blurred = convolve(x_pred, kernel, mode='reflect')\n",
    "    except ImportError:\n",
    "        # Fallback if scipy is not installed\n",
    "        blurred = x_pred\n",
    "        \n",
    "    # Add a small amount of random noise\n",
    "    noise = np.random.normal(0, 0.02, x_pred.shape)\n",
    "    y_pred = blurred + noise\n",
    "    \n",
    "    return np.clip(y_pred, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077d07b",
   "metadata": {},
   "source": [
    "### 3D Validation: Downsampled Overview\n",
    "\n",
    "**The Goal:** To get a quick, high-level \"sanity check\" of the model's 3D output across the entire volume.\n",
    "\n",
    "**The Technique:** We take each of the high-resolution volumes (e.g., 128x128x128) and downsample them to a much smaller size (e.g., 64x64x64). These smaller volumes are then rendered side-by-side using Plotly.\n",
    "\n",
    "**Why it's useful:**\n",
    "* **Performance:** Smaller volumes render very quickly in the browser, providing immediate feedback without performance lag.\n",
    "* **Full Context:** You can see the entire spatial domain at once, which is great for identifying large-scale structural problems or biases in the model's output.\n",
    "* **Browser-Friendly:** This is the most reliable way to visualize multiple 3D volumes on a wide range of hardware, as it keeps memory and GPU usage low.\n",
    "\n",
    "**The Trade-off:**\n",
    "* **Loss of Detail:** Fine-grained features, sharp edges, and subtle details in the geology will be blurred or lost during the downsampling process. This view is not suitable for detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b0aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_downsampled_comparison(volumes: Dict[str, np.ndarray]) -> go.Figure:\n",
    "    \"\"\"Downsamples volumes and returns a side-by-side Plotly figure.\"\"\"\n",
    "    target_shape = (64, 64, 64)\n",
    "    downsampled_volumes = {}\n",
    "    for name, data in volumes.items():\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        resized_data = resize(data, target_shape, anti_aliasing=True)\n",
    "        downsampled_volumes[name] = resized_data * (data_max - data_min) + data_min\n",
    "    fig = make_subplots(rows=1, cols=5, specs=[[{'type': 'volume'}] * 5], subplot_titles=list(downsampled_volumes.keys()))\n",
    "    for i, (name, data) in enumerate(downsampled_volumes.items()):\n",
    "        fig.add_trace(go.Volume(x=np.arange(data.shape[0]), y=np.arange(data.shape[1]), z=np.arange(data.shape[2]), value=data.flatten(), isomin=np.min(data), isomax=np.max(data), opacity=0.1, surface_count=15, colorscale='RdBu' if 'Residual' in name else 'viridis'), row=1, col=i + 1)\n",
    "    fig.update_layout(title_text=\"Downsampled 3D Comparison\", height=400, margin=dict(t=50, b=10, l=10, r=10))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77f75e",
   "metadata": {},
   "source": [
    "### 3D Validation: Cropped High-Detail View\n",
    "\n",
    "**The Goal:** To inspect a specific region of the 3D volume at full resolution, preserving all the fine details.\n",
    "\n",
    "**The Technique:** Instead of resizing the entire volume, we extract a smaller sub-volume (e.g., a 64x64x64 cube) from a consistent location (like the center) of the original, high-resolution data. These full-detail crops are then rendered side-by-side.\n",
    "\n",
    "**Why it's useful:**\n",
    "* **Maximum Detail:** You see the data exactly as it is, with no loss of resolution. This is crucial for validating the texture, sharpness, and small-scale accuracy of the model's predictions.\n",
    "* **Targeted Analysis:** It allows you to focus on a specific known feature or a problematic area identified in the downsampled view.\n",
    "\n",
    "**The Trade-off:**\n",
    "* **Loss of Context:** You are only seeing a small fraction of the total volume and lose the broader structural context. An issue might seem small in the crop but could be part of a much larger problem not visible in the limited view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c8406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cropped_comparison(volumes: Dict[str, np.ndarray]) -> go.Figure:\n",
    "    \"\"\"Crops the center of volumes and returns a side-by-side Plotly figure.\"\"\"\n",
    "    crop_size = 64\n",
    "    cropped_volumes = {}\n",
    "    for name, data in volumes.items():\n",
    "        if all(dim >= crop_size for dim in data.shape):\n",
    "            center = [dim // 2 for dim in data.shape]; start = [c - crop_size // 2 for c in center]; end = [c + crop_size // 2 for c in center]\n",
    "            cropped_volumes[name] = data[start[0]:end[0], start[1]:end[1], start[2]:end[2]]\n",
    "        else:\n",
    "            cropped_volumes[name] = data\n",
    "    fig = make_subplots(rows=1, cols=5, specs=[[{'type': 'volume'}] * 5], subplot_titles=list(cropped_volumes.keys()))\n",
    "    for i, (name, data) in enumerate(cropped_volumes.items()):\n",
    "        fig.add_trace(go.Volume(x=np.arange(data.shape[0]), y=np.arange(data.shape[1]), z=np.arange(data.shape[2]), value=data.flatten(), isomin=np.min(data), isomax=np.max(data), opacity=0.1, surface_count=15, colorscale='RdBu' if 'Residual' in name else 'viridis'), row=1, col=i + 1)\n",
    "    fig.update_layout(title_text=\"Cropped (Full-Res) 3D Comparison\", height=400, margin=dict(t=50, b=10, l=10, r=10))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06aea2",
   "metadata": {},
   "source": [
    "### 3D Validation: High-Fidelity Single Volume Render\n",
    "\n",
    "**The Goal:** To generate the highest-quality interactive visualization possible for a single, critical 3D volume.\n",
    "\n",
    "**The Technique:** We use a specialized scientific visualization library like PyVista or ipyvolume. These libraries are built for performance and offer advanced rendering features. The process involves creating a render, exporting it to a self-contained HTML file, and logging that file to W&B.\n",
    "\n",
    "**Why it's useful:**\n",
    "* **Best Visual Quality:** These libraries use sophisticated rendering techniques (e.g., volume ray casting) to produce much clearer and more detailed visualizations than general-purpose plotting tools.\n",
    "* **Advanced Controls:** They often provide more advanced tools for manipulating the view, such as adjusting color maps and lighting, which can be crucial for geological interpretation.\n",
    "\n",
    "**The Trade-off:**\n",
    "* **Single-Volume Focus:** This method is best for inspecting one volume at a time. Comparing multiple volumes requires logging separate viewers, which can be less convenient than a side-by-side view.\n",
    "* **Larger Artifacts:** The resulting HTML files can be larger than a simple Plotly JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7868f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyvista_render(volume: np.ndarray, title: str) -> str:\n",
    "    \"\"\"Renders a single volume using PyVista and returns the HTML as a string.\"\"\"\n",
    "    try:\n",
    "        grid = pv.ImageData(dimensions=volume.shape); grid[\"values\"] = volume.flatten(order=\"F\")\n",
    "        plotter = pv.Plotter(off_screen=True); plotter.add_volume(grid, cmap='RdBu' if 'Residual' in title else 'viridis', opacity='sigmoid', shade=True)\n",
    "        plotter.add_axes(); plotter.camera_position = 'iso'\n",
    "        html_filename = f\"{title}.html\"; plotter.export_html(html_filename, progressive=True)\n",
    "        with open(html_filename, 'r') as f: html_content = f.read()\n",
    "        os.remove(html_filename)\n",
    "        return html_content\n",
    "    except Exception as e:\n",
    "        return f\"<p>PyVista rendering failed: {e}</p>\"\n",
    "\n",
    "def create_ipyvolume_render(volume: np.ndarray, title: str) -> str:\n",
    "    \"\"\"Renders a single volume using ipyvolume and returns the HTML as a string.\"\"\"\n",
    "    try:\n",
    "        ipv.clear(); ipv.quickvolshow(volume, level_width=0.1, opacity=0.03, data_min=np.min(volume), data_max=np.max(volume))\n",
    "        html_filename = f\"{title}_ipv.html\"; ipv.save(html_filename)\n",
    "        with open(html_filename, 'r') as f: html_content = f.read()\n",
    "        os.remove(html_filename)\n",
    "        return html_content\n",
    "    except Exception as e:\n",
    "        return f\"<p>ipyvolume rendering failed: {e}</p>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2ba0e",
   "metadata": {},
   "source": [
    "## 3. The Core Training Function with W&B Integration\n",
    "\n",
    "This function encapsulates the entire training and evaluation workflow. It serves as a blueprint for a reproducible, auditable, and transparent ML lifecycle. Each section is clearly marked to show how a specific W&B feature is used to track, version, and evaluate the model, turning a standard training script into an enterprise-ready system of record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40728477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conditional_diffusion(config=None):\n",
    "    \"\"\"\n",
    "    Train a conditional diffusion model for geological structure generation.\n",
    "    This function is instrumented with W&B to track the entire lifecycle.\n",
    "    \"\"\"\n",
    "    # ===================================================================\n",
    "    # 1. W&B SETUP: Initialize Run and Centralize Configuration\n",
    "    #    - wandb.init() starts a new run to track this experiment.\n",
    "    #    - wandb.config pulls hyperparameter settings, making them available to sweeps.\n",
    "    # ===================================================================\n",
    "    # Use the example config we defined earlier \n",
    "    config = example_config\n",
    "\n",
    "    # Initialize a new W&B run\n",
    "    run = wandb.init(\n",
    "        entity=ENTITY,\n",
    "        project=PROJECT,\n",
    "        config=config, \n",
    "        # job_type and tags are powerful organizational tools that make it easy\n",
    "        # to filter, group, and compare runs across a large project.\n",
    "        job_type=\"training\",\n",
    "        tags=[\"conditional-diffusion\"]\n",
    "    )\n",
    "\n",
    "    # Use the config from W&B (this allows sweeps to override values)\n",
    "    config = wandb.config\n",
    "\n",
    "    # ===================================================================\n",
    "    # 2. W&B ARTIFACTS: Versioning and Loading the Dataset\n",
    "    #    - run.use_artifact() declares a dependency on a specific dataset version.\n",
    "    #    - This creates a lineage graph, giving us a full audit trail.\n",
    "    # ===================================================================\n",
    "    # Load CigKarst dataset from W&B Registry\n",
    "    \n",
    "    \n",
    "    # run.use_artifact() creates a direct link to the dataset version used for this run.\n",
    "    # This automatically generates a complete, visual data-to-model lineage graph,\n",
    "    # which is essential for auditability and debugging.\n",
    "    artifact = run.use_artifact('wandb-registry-dataset/CigKarst:v0', type='dataset')\n",
    "    artifact_dir = artifact.download()\n",
    "\n",
    "    # Load geological samples from the dataset\n",
    "    geological_samples = []\n",
    "    metadata_path = Path(artifact_dir) / \"dataset_metadata.npz\"\n",
    "\n",
    "    if metadata_path.exists():\n",
    "        metadata = np.load(metadata_path, allow_pickle=True)\n",
    "        samples_data = metadata['samples'].tolist()\n",
    "        for sample_info in samples_data:\n",
    "            seismic_file = Path(artifact_dir) / sample_info['seismic_file']\n",
    "            karst_file = Path(artifact_dir) / sample_info['karst_file']\n",
    "            if seismic_file.exists() and karst_file.exists():\n",
    "                seismic_data = np.load(seismic_file)\n",
    "                karst_data = np.load(karst_file)\n",
    "                sample = {\n",
    "                    'seismic': seismic_data['patch'],\n",
    "                    'karst': karst_data['patch'],\n",
    "                    'sample_id': sample_info['sample_id'],\n",
    "                    'coordinates': sample_info['coordinates'],\n",
    "                    'source': sample_info['source_volume']\n",
    "                }\n",
    "                geological_samples.append(sample)\n",
    "        print(f\"Loaded {len(geological_samples)} real geological samples from CigKarst\")\n",
    "    else:\n",
    "        print(\"Metadata file not found in artifact\")\n",
    "        run.finish()\n",
    "        return None\n",
    "\n",
    "    # Select a fixed set of samples for consistent validation across runs\n",
    "    good_sample_ids = [\"volume_0_patch_1\", \"volume_0_patch_3\", \"volume_1_patch_0\"]\n",
    "    fixed_samples = [s for s in geological_samples if s['sample_id'] in good_sample_ids]\n",
    "    if len(fixed_samples) != len(good_sample_ids):\n",
    "        raise ValueError(f\"Error: Could not find all specified good samples.\")\n",
    "    print(f\"Selected {len(fixed_samples)} pre-validated samples for tracking.\")\n",
    "\n",
    "    # Track best model\n",
    "    best_validation_loss = float('inf')\n",
    "\n",
    "    # ===================================================================\n",
    "    # 3. W&B TRAINING LOOP: Logging Live Metrics\n",
    "    #    - run.log() is called inside the loop to stream metrics in real-time.\n",
    "    #    - This allows us to monitor model performance and system utilization live from the dashboard.\n",
    "    # ===================================================================\n",
    "    for epoch in range(config.get(\"epochs\", 10)):\n",
    "        print(f\"Epoch {epoch}: Simulating conditional diffusion training...\")\n",
    "        batches_per_epoch = config.get(\"batches_per_epoch\", 20)\n",
    "        \n",
    "        for batch in range(batches_per_epoch):\n",
    "            step = epoch * batches_per_epoch + batch\n",
    "            # Simulate training progress and calculate synthetic losses\n",
    "            noise_pred_loss = generate_synthetic_loss(step)\n",
    "            condition_mse = generate_synthetic_loss(step * 1.5) * 0.8\n",
    "            total_loss = 0.5 * noise_pred_loss + 0.3 * condition_mse\n",
    "\n",
    "            # Prepare log dictionary for training metrics\n",
    "            log_dict = {\n",
    "                \"train/noise_prediction_loss\": noise_pred_loss,\n",
    "                \"train/condition_mse\": condition_mse,\n",
    "                \"train/total_loss\": total_loss,\n",
    "                \"train/learning_rate\": config.get(\"learning_rate\", 1e-3) * (0.95 ** (epoch // 3)),\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            \n",
    "            # SINGLE wandb.log call per training step. W&B automatically captures system\n",
    "            # metrics (CPU/GPU utilization, memory) alongside your custom metrics, providing\n",
    "            # a holistic view to diagnose performance bottlenecks in real-time.\n",
    "            run.log(log_dict)\n",
    "\n",
    "        # ===================================================================\n",
    "        # 4. W&B VALIDATION: Logging Rich Media and Tables\n",
    "        #    - At the end of each epoch, we log qualitative results.\n",
    "        #    - wandb.Image() for visual comparison.\n",
    "        #    - wandb.Html() for custom, interactive Plotly charts.\n",
    "        #    - wandb.Table() to create structured, sortable tables of predictions.\n",
    "        # ===================================================================\n",
    "        val_total_loss = generate_synthetic_loss(epoch * 50) * 0.85\n",
    "        \n",
    "        # wandb.Table creates a rich, interactive table in the UI. This allows for\n",
    "        # sorting and filtering results, and comparing images, plots, and metrics\n",
    "        # side-by-side across different runs—all within a single view.\n",
    "        validation_table = wandb.Table(columns=[\n",
    "            \"epoch\", \"sample_id\", \"seismic_input\", \"ground_truth\",\n",
    "            \"prediction\", \"residual_map\", \"well_log_comparison\", \"condition_mse\", \"ssim_score\", \"log_correlation\"])\n",
    "            \n",
    "        total_condition_mse = 0\n",
    "\n",
    "        # --- NEW: Create visualizations for a small BATCH of validation samples ---\n",
    "        # We will create a unique key for each visualization in the log dictionary.\n",
    "        visualizations_log = {}\n",
    "        \n",
    "        for sample in fixed_samples:\n",
    "            prediction = simulate_conditional_diffusion_progress(\n",
    "                sample['seismic'], sample['karst'], epoch, config.get(\"epochs\", 10))\n",
    "            sample_id = sample['sample_id']\n",
    "            \n",
    "            # Generate the necessary volumes for this specific sample\n",
    "            prediction_3d = simulate_conditional_diffusion_progress(sample['seismic'], sample['karst'], epoch, config.get(\"epochs\", 10))\n",
    "            y_pred_3d = simulate_forward_model(prediction_3d)\n",
    "            volumes_for_viz = {\n",
    "                \"1_Input_Condition_Y\": sample['seismic'],\n",
    "                \"2_Ground_Truth_X\": sample['karst'],\n",
    "                \"3_AI_Prediction_X_pred\": prediction_3d,\n",
    "                \"4_AI_Condition_Y_pred\": y_pred_3d,\n",
    "                \"5_Residual_Y_pred_minus_Y\": y_pred_3d - sample['seismic']\n",
    "            }\n",
    " \n",
    "            # --- NEW: Call visualization helper functions ---\n",
    "            # Call the create functions and add the objects to our log dictionary\n",
    "            # using unique keys that include the sample_id.\n",
    "            visualizations_log[f\"3D_Views/{sample_id}/Downsampled\"] = create_downsampled_comparison(volumes_for_viz)\n",
    "            visualizations_log[f\"3D_Views/{sample_id}/Cropped\"] = create_cropped_comparison(volumes_for_viz)\n",
    "            visualizations_log[f\"3D_Views/{sample_id}/PyVista_Residual\"] = wandb.Html(create_pyvista_render(volumes_for_viz[\"5_Residual_Y_pred_minus_Y\"], f\"Residual_{sample_id}\"))\n",
    "            visualizations_log[f\"3D_Views/{sample_id}/ipyvolume_Prediction\"] = wandb.Html(create_ipyvolume_render(volumes_for_viz[\"3_AI_Prediction_X_pred\"], f\"Prediction_{sample_id}\"))\n",
    "\n",
    "            \n",
    "            # end\n",
    "\n",
    "            # Prepare data for logging (2D slices, logs, etc.)\n",
    "            slice_idx = sample['seismic'].shape[2] // 2\n",
    "            seismic_slice = sample['seismic'][:, :, slice_idx]\n",
    "            gt_slice = sample['karst'][:, :, slice_idx]\n",
    "            pred_slice = prediction[:, :, slice_idx]\n",
    "            residual_slice = pred_slice - gt_slice\n",
    "            max_abs_val = np.max(np.abs(residual_slice))\n",
    "            residual_norm = (residual_slice + max_abs_val) / (2 * max_abs_val) if max_abs_val > 0 else np.zeros_like(residual_slice)\n",
    "            \n",
    "            # Metrics\n",
    "            condition_mse = np.mean((pred_slice - gt_slice) ** 2)\n",
    "            total_condition_mse += condition_mse\n",
    "            ssim_score = ssim(gt_slice, pred_slice, data_range=1.0)\n",
    "            \n",
    "            # Well Logs\n",
    "            well_log_depth = np.arange(prediction.shape[0]) * 25\n",
    "            well_x, well_y = prediction.shape[1] // 2, prediction.shape[2] // 2\n",
    "            gt_well_log = sample['karst'][:, well_x, well_y]\n",
    "            pred_well_log = prediction[:, well_x, well_y]\n",
    "            log_correlation = np.corrcoef(gt_well_log, pred_well_log)[0, 1] if np.std(gt_well_log) > 0 and np.std(pred_well_log) > 0 else 0.0\n",
    "            \n",
    "            # Add data to the validation table\n",
    "            validation_table.add_data(\n",
    "                epoch,\n",
    "                sample['sample_id'],\n",
    "                wandb.Image(normalize_for_visualization(seismic_slice)),\n",
    "                wandb.Image(normalize_for_visualization(gt_slice)),\n",
    "                wandb.Image(normalize_for_visualization(pred_slice)),\n",
    "                wandb.Image(residual_norm, caption=\"Residual Map\"),\n",
    "                plot_well_log_comparison(gt_well_log, pred_well_log, well_log_depth),\n",
    "                condition_mse,\n",
    "                ssim_score,\n",
    "                log_correlation\n",
    "            )\n",
    "\n",
    "        # Log validation metrics ONCE per epoch\n",
    "        # Log all epoch-level data in a single call\n",
    "        epoch_log_data = {\"val/total_loss\": val_total_loss, \"val/avg_condition_mse\": total_condition_mse / len(fixed_samples), \"advanced_validation_table\": validation_table, \"epoch\": epoch}\n",
    "        epoch_log_data.update(visualizations_log) # Add the dictionary of 3D views\n",
    "        run.log(epoch_log_data)\n",
    "\n",
    "        # ===================================================================\n",
    "        # 5. W&B MODEL REGISTRY: Versioning Models as Artifacts\n",
    "        #    - We check if the model has improved and, if so, save it.\n",
    "        #    - wandb.Artifact() creates a versioned package of model files and metadata.\n",
    "        #    - run.link_artifact() registers the model in the W&B Model Registry,\n",
    "        #      assigning it an alias like \"best\" or \"staging\" for easy retrieval.\n",
    "        # ===================================================================\n",
    "        if val_total_loss < best_validation_loss:\n",
    "            best_validation_loss = val_total_loss\n",
    "            print(f\"New best model at epoch {epoch}! Validation loss: {val_total_loss:.4f}\")\n",
    "            \n",
    "            checkpoint_artifact = wandb.Artifact(\n",
    "                name=\"conditional-diffusion-checkpoint\",\n",
    "                type=\"model\",\n",
    "                description=f\"Best conditional diffusion model - epoch {epoch}\",\n",
    "                metadata={\n",
    "                    \"epoch\": epoch,\n",
    "                    \"validation_loss\": round(val_total_loss, 4),\n",
    "                    \"dataset_artifact\": artifact.name\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            checkpoint_path = f\"best_model_epoch_{epoch}.pth\"\n",
    "            Path(checkpoint_path).write_text(f\"Best model checkpoint at epoch {epoch}\")\n",
    "            checkpoint_artifact.add_file(checkpoint_path)\n",
    "            \n",
    "            # Log the artifact and link it to the registry\n",
    "            logged_artifact = run.log_artifact(checkpoint_artifact, aliases=[\"best\"])\n",
    "           \n",
    "            # run.link_artifact() registers the model in the W&B Model Registry. Aliases\n",
    "            # like \"staging\" or \"production\" create pointers for CI/CD systems, automating\n",
    "            # the path from training to deployment.\n",
    "            run.link_artifact(\n",
    "                artifact=logged_artifact,\n",
    "                target_path=\"wandb-registry-model/conditional-diffusion\",\n",
    "                aliases=[\"staging\"]\n",
    "            )\n",
    "            os.remove(checkpoint_path)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6. W&B CLEANUP: Finalizing the Run\n",
    "    #    - run.finish() marks the run as complete and uploads any remaining data.\n",
    "    # ===================================================================\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5ad2f",
   "metadata": {},
   "source": [
    "## 4. Execute a Single Training Run\n",
    "\n",
    "Now we call our main function to execute a single, baseline training run.\n",
    "\n",
    "**Action:** When you run this cell, click the W&B link that appears in the output. This will take you to the live dashboard where you can see all the metrics, images, and tables being logged in real-time. This is the central hub for our experiment.\n",
    "\n",
    "What to look for in the UI:\n",
    "\n",
    "Live Metrics: Watch the loss curves update in real-time. No need to wait for the job to finish.\n",
    "\n",
    "System Monitoring: Check the system tab to see live CPU/GPU utilization charts, automatically captured by W&B.\n",
    "\n",
    "Interactive Tables: At the end of each epoch, a new row will appear in the advanced_validation_table. Click on the images to expand them and hover over the charts to interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddae711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/condition_mse</td><td>██▇▆▆▆▅▅▅▄▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>██▆▇▆▅▅▆▄▄▄▄▃▂▃▂▂▂▁▁</td></tr><tr><td>train/total_loss</td><td>██▆▇▆▆▅▆▄▄▄▄▃▂▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train/condition_mse</td><td>1.03949</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/noise_prediction_loss</td><td>1.37596</td></tr><tr><td>train/total_loss</td><td>0.99983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-firebrand-45</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-scratchpad/runs/hgt7qhsk' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad/runs/hgt7qhsk</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-scratchpad' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad</a><br>Synced 8 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_105605-hgt7qhsk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/al/Documents/gitstuff/shell-tenet-28July2025/wandb/run-20250801_105829-q0tlcip8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb_emea/workshop-scratchpad/runs/q0tlcip8' target=\"_blank\">bright-smoke-46</a></strong> to <a href='https://wandb.ai/wandb_emea/workshop-scratchpad' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb_emea/workshop-scratchpad' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb_emea/workshop-scratchpad/runs/q0tlcip8' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad/runs/q0tlcip8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   49 of 49 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 real geological samples from CigKarst\n",
      "Selected 3 pre-validated samples for tracking.\n",
      "Epoch 0: Simulating conditional diffusion training...\n",
      "New best model at epoch 0! Validation loss: 1.3475\n",
      "Epoch 1: Simulating conditional diffusion training...\n",
      "New best model at epoch 1! Validation loss: 0.9296\n",
      "Epoch 2: Simulating conditional diffusion training...\n",
      "New best model at epoch 2! Validation loss: 0.6674\n",
      "Epoch 3: Simulating conditional diffusion training...\n",
      "New best model at epoch 3! Validation loss: 0.5076\n",
      "Epoch 4: Simulating conditional diffusion training...\n",
      "New best model at epoch 4! Validation loss: 0.3539\n",
      "Epoch 5: Simulating conditional diffusion training...\n",
      "New best model at epoch 5! Validation loss: 0.2714\n",
      "Epoch 6: Simulating conditional diffusion training...\n",
      "New best model at epoch 6! Validation loss: 0.1898\n",
      "Epoch 7: Simulating conditional diffusion training...\n",
      "Epoch 8: Simulating conditional diffusion training...\n",
      "New best model at epoch 8! Validation loss: 0.1119\n",
      "Epoch 9: Simulating conditional diffusion training...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▇▇███</td></tr><tr><td>train/condition_mse</td><td>████▇▇▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█████████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>train/noise_prediction_loss</td><td>███▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/total_loss</td><td>██▆▆▆▆▆▆▆▅▄▄▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>val/avg_condition_mse</td><td>█▇██▅▅▄▁▁▁</td></tr><tr><td>val/total_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train/condition_mse</td><td>0.21489</td></tr><tr><td>train/learning_rate</td><td>0.00086</td></tr><tr><td>train/noise_prediction_loss</td><td>0.4702</td></tr><tr><td>train/total_loss</td><td>0.29957</td></tr><tr><td>val/avg_condition_mse</td><td>0.00075</td></tr><tr><td>val/total_loss</td><td>0.116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-smoke-46</strong> at: <a href='https://wandb.ai/wandb_emea/workshop-scratchpad/runs/q0tlcip8' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad/runs/q0tlcip8</a><br> View project at: <a href='https://wandb.ai/wandb_emea/workshop-scratchpad' target=\"_blank\">https://wandb.ai/wandb_emea/workshop-scratchpad</a><br>Synced 8 W&B file(s), 130 media file(s), 119 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250801_105829-q0tlcip8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with default config\n",
    "train_conditional_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12db70",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Sweeps: Enterprise-Scale Optimization\n",
    "\n",
    "Running one experiment manually is not efficient. To find the optimal model, we need to explore the hyperparameter space. W&B Sweeps provide a powerful, scalable, and fully integrated way to automate this process.\n",
    "\n",
    "Instead of writing custom loops or relying on external optimization libraries, you can define a search strategy in a simple configuration file. W&B then coordinates the search, distributing jobs to any number of agents and providing powerful visualizations to track the results in real-time.\n",
    "\n",
    "First, we define a `sweep_config`. This configuration specifies the search strategy (Bayesian), the metric to optimize (validation loss), and the range of hyperparameters to test. We also include an early termination strategy to save compute resources by stopping underperforming runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Sweep Configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # Bayesian optimization for efficient search\n",
    "    \"metric\": {\n",
    "        \"name\": \"val/total_loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        # Key training parameters\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 5e-3\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [4, 8, 16]\n",
    "        },\n",
    "\n",
    "        # Diffusion-specific parameters\n",
    "        \"noise_schedule\": {\n",
    "            \"values\": [\"cosine\", \"linear\", \"sigmoid\"]\n",
    "        },\n",
    "        \"conditioning_strength\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.6,\n",
    "            \"max\": 0.95\n",
    "        },\n",
    "\n",
    "        # Fixed parameters for the workshop\n",
    "        \"epochs\": {\n",
    "            \"value\": 10\n",
    "        },\n",
    "        \"batches_per_epoch\": {\n",
    "            \"value\": 20\n",
    "        }\n",
    "    },\n",
    "    # Add early stopping to be more efficient with resources. This tells the W&B\n",
    "    # sweep controller to automatically stop poor-performing runs early, saving\n",
    "    # significant compute time and cost.\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3, # Stop runs that don't show improvement after 3 epochs\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Initialize the Sweep\n",
    "# This command creates the sweep controller in the W&B cloud. It acts as a\n",
    "# central coordinator that agents can query for new jobs.\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config,\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT\n",
    ")\n",
    "\n",
    "print(f\"✅ Sweep created successfully! Sweep ID: {sweep_id}\")\n",
    "print(f\"🧹 View and manage your sweep here: https://wandb.ai/{ENTITY}/{PROJECT}/sweeps/{sweep_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07322a0",
   "metadata": {},
   "source": [
    "## 6. Launch a W&B Agent\n",
    "\n",
    "Now that the sweep is initialized, we launch an agent. The agent is a simple, stateless worker that will:\n",
    "1.  Ask the W&B sweep server for a set of hyperparameters.\n",
    "2.  Run our `train_conditional_diffusion` function with those hyperparameters.\n",
    "3.  Repeat until the sweep is finished.\n",
    "\n",
    "This architecture is incredibly scalable. You can launch agents on your laptop, on a fleet of cloud VMs, or in a Kubernetes cluster, and they will all coordinate through the central sweep controller to work on the same optimization problem\n",
    "\n",
    "We will start one agent to run 5 experiments for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run the Sweep Agent\n",
    "# This single command connects a worker to the sweep controller. The agent\n",
    "# automatically fetches a configuration, executes the training function,\n",
    "# and reports the results back, requiring zero manual orchestration.\n",
    "wandb.agent(sweep_id, function=train_conditional_diffusion, count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b8187",
   "metadata": {},
   "source": [
    "## 7. Programmatic Executive Reports: From Model to Boardroom\n",
    "\n",
    "The final step is to bridge the gap between technical results and business stakeholders. This is often the \"last mile\" problem in ML, where valuable insights get lost in translation. Manually creating reports is slow, error-prone, and creates static documents that are quickly outdated.\n",
    "\n",
    "The W&B Report API allows us to programmatically generate dynamic, data-driven reports directly from our experiments. This transforms our experimental results from raw data into a persistent, shareable decision-making asset. This provides a transparent, repeatable, and always up-to-date summary for governance and high-stakes investment decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attempting to create a programmatic report...\")\n",
    "print(f\"Using entity: '{ENTITY}', project: '{PROJECT}'\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Find the Best Run ---\n",
    "    # We'll create the report based on the best-performing run from our latest experiments.\n",
    "    api = wandb.Api()\n",
    "    # The W&B API allows for powerful, programmatic querying of all experimental data.\n",
    "    # Here, we filter for our specific runs and sort them by the target metric.\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(\n",
    "        path=f\"{ENTITY}/{PROJECT}\",\n",
    "        order=\"-created_at\",\n",
    "        filters={\"tags\": \"conditional-diffusion\", \"state\": \"finished\"}\n",
    "    )\n",
    "    \n",
    "    if not runs:\n",
    "        raise ValueError(\"No finished runs with the 'conditional-diffusion' tag found.\")\n",
    "        \n",
    "    best_run = sorted(runs, key=lambda run: run.summary.get(\"val/total_loss\", float('inf')))[0]\n",
    "    print(f\"Generating report based on best run: {best_run.name} (ID: {best_run.id})\")\n",
    "    print(f\"Best validation loss: {best_run.summary.get('val/total_loss'):.4f}\")\n",
    "\n",
    "    # --- 2. Create the Report Object ---\n",
    "    report = wr.Report(\n",
    "        entity=ENTITY,\n",
    "        project=PROJECT,\n",
    "        title=f\"Geological ML Model Performance - {time.strftime('%Y-%m-%d')}\",\n",
    "        description=f\"Automated summary for the conditional diffusion model. Best run: {best_run.name}.\",\n",
    "    )\n",
    "\n",
    "    # --- 3. Define the Report Structure ---\n",
    "    report.blocks = [\n",
    "        wr.H1(\"Executive Summary: Geological Interpretation Model\"),\n",
    "        wr.P(f\"\"\"\n",
    "        This report summarizes the performance of the conditional diffusion model trained for geological structure generation. \n",
    "        The model was trained for **{best_run.config.get('epochs', 'N/A')} epochs**, achieving a final validation loss of \n",
    "        **{best_run.summary.get('val/total_loss', 0):.4f}**. \n",
    "        This automated report was generated on {time.strftime('%B %d, %Y')}.\n",
    "        \"\"\"),\n",
    "        \n",
    "        wr.H2(\"Key Performance Metrics\"),\n",
    "        wr.P(\"The following charts show the model's learning progression and final performance on the validation set.\"),\n",
    "        \n",
    "        # --- 4. Add Panels for Metrics ---\n",
    "        # PanelGrids pull visualizations directly from one or more runs. The report\n",
    "        # remains a live document; if you re-run the experiment, the charts in the\n",
    "        # report can be updated automatically.\n",
    "        wr.PanelGrid(\n",
    "            runsets=[wr.Runset(entity=ENTITY, project=PROJECT, name=best_run.id)],\n",
    "            panels=[\n",
    "                wr.LinePlot(\n",
    "                    title=\"Validation Loss Over Epochs\",\n",
    "                    x=\"epoch\",\n",
    "                    y=[\"val/total_loss\"],\n",
    "                    layout={'w': 24, 'h': 12} # Make this chart wider\n",
    "                ),\n",
    "                wr.ScalarChart(\n",
    "                    title=\"Best Final Validation Loss\",\n",
    "                    metric=\"val/total_loss\",\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        wr.H2(\"Detailed Validation Analysis\"),\n",
    "        wr.P(\"The table below provides a detailed, interactive breakdown of the model's performance on our validation samples from the final epoch.\"),\n",
    "        \n",
    "        # --- 5. Add Panel for the Validation Table ---\n",
    "        # We can embed the entire interactive media table we created during validation\n",
    "        # directly into the final report for detailed, qualitative analysis.\n",
    "        wr.PanelGrid(\n",
    "            runsets=[wr.Runset(entity=ENTITY, project=PROJECT, name=best_run.id)],\n",
    "            panels=[\n",
    "                wr.WeavePanelSummaryTable(\n",
    "                    table_name=\"advanced_validation_table\", \n",
    "                    layout={'w': 24, 'h': 16}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        wr.H2(\"Model Governance & Next Steps\"),\n",
    "        wr.P(f\"\"\"\n",
    "        The best model artifact from this run has been versioned and linked to the Model Registry, ensuring a complete audit trail.\n",
    "        - **Best Model Run Link**: You can view the full experiment details here: [`{best_run.name}`](https://wandb.ai/{ENTITY}/{PROJECT}/runs/{best_run.id})\n",
    "        - **Model Artifact Name**: `conditional-diffusion-checkpoint`\n",
    "        \n",
    "        **Next Steps**:\n",
    "        1. Review model performance with geological subject matter experts.\n",
    "        2. Promote the model from 'Staging' to a 'Production' alias in the registry for further testing.\n",
    "        3. Begin planning for deployment to a validation environment.\n",
    "        \"\"\")\n",
    "    ]\n",
    "\n",
    "    # --- 6. Save and Publish the Report ---\n",
    "    # report.save() publishes the report to your W&B workspace, generating a\n",
    "    # stable, shareable URL for stakeholders.\n",
    "    report.save()\n",
    "\n",
    "    print(f\"\\n✅ Executive report created successfully!\")\n",
    "    print(f\"📊 Title: {report.title}\")\n",
    "    print(f\"🔗 URL: {report.url}\")\n",
    "    print(f\"📧 Ready for stakeholder distribution.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ Report creation failed: {e}\")\n",
    "    print(\"This might be due to:\")\n",
    "    print(\"- No finished runs found in the project with the correct tag.\")\n",
    "    print(\"- Incorrect API permissions or W&B team/enterprise settings.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
